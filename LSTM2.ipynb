{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5biTBwa4nrIR",
        "outputId": "9fe2f4bd-a987-4bd7-f2d5-5f0a77a96fc7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jul 26 03:38:15 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    25W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av2XIy3-nuwY",
        "outputId": "f2aea143-bb71-4a8e-fb7e-5b11cc12d5db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlS9Uvs8mqJC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pandas_datareader as pdr\n",
        "from datetime import datetime,timedelta\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense ,LSTM, Dropout,Bidirectional,TimeDistributed\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from tensorflow import expand_dims\n",
        "from tensorflow.keras.losses import Huber\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from os.path import join\n",
        "from tensorflow import constant\n",
        "from time import sleep\n",
        "from prophet import Prophet\n",
        "#import FinanceDataReader as fdr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('/content/drive/MyDrive/2023_1st_vac/KRX_DATA/train.csv')"
      ],
      "metadata": {
        "id": "AaqZOaT3nwOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_date(date_str):\n",
        "  return pd.to_datetime(date_str, format=\"%Y%m%d\").strftime(\"%Y-%m-%d\")\n",
        "##make sliced=[sliced]\n",
        "data[\"일자\"] =data[\"일자\"].apply(convert_date)"
      ],
      "metadata": {
        "id": "lg9M4XJWxM7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prescaler\n",
        "def getAOC(data):\n",
        "  AOC = []\n",
        "  close = data['종가']\n",
        "  close_pre = close.shift(1)\n",
        "\n",
        "  AOC.append(0)\n",
        "\n",
        "  # aoc = (금일 종가 - 전일 종가) / 전일 종가\n",
        "  for i in range(1, len(close)):\n",
        "    aoc_value = ((close[i] - close_pre[i]) / close_pre[i]) * 100\n",
        "    AOC.append(aoc_value)\n",
        "\n",
        "  return AOC\n",
        "\n",
        "#sort data by \"종목명\"\n",
        "subject_Data=data.sort_values(by=\"종목코드\",inplace=False)\n",
        "subject_Data.head()\n",
        "subject_Data.columns\n",
        "\n",
        "\n",
        "pv_s_data=pd.pivot_table(subject_Data,values=['거래량', '시가', '고가', '저가', '종가'],index=['종목코드','일자'])\n",
        "pv_s_data[\"AOC\"] = getAOC(pv_s_data)\n",
        "\n",
        "divided = pv_s_data.index.get_level_values('종목코드').unique()\n",
        "\n",
        "sliced_dataframes = []\n",
        "\n",
        "for i in divided:\n",
        "    sliced_data = pv_s_data.loc[i]\n",
        "    sliced_dataframe = sliced_data.reset_index()\n",
        "    sliced_dataframes.append(sliced_dataframe)\n",
        "\n",
        "for s in sliced_dataframes:\n",
        "  s.set_index('일자',inplace=True)"
      ],
      "metadata": {
        "id": "AIaGIBggn0EB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sliced_dataframes[0]"
      ],
      "metadata": {
        "id": "E74yHSmYzfkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## sorting labels\n",
        "labels=data[['종목코드','일자']]\n",
        "labels = labels.sort_values(by=['종목코드','일자'])\n",
        "labels=labels.drop('일자',axis=1)\n",
        "labels=labels.drop_duplicates('종목코드')\n",
        "data.sort_values(by=['종목코드',\"일자\"],inplace=True)"
      ],
      "metadata": {
        "id": "Ln4tIZyrn_CL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_lis=[]\n",
        "for label in labels:\n",
        "  label_lis.append(label)"
      ],
      "metadata": {
        "id": "XZLH8UxjRMln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model shells"
      ],
      "metadata": {
        "id": "84N83sUqC2Ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.options.display.float_format = '{:.5f}'.format\n",
        "\n",
        "class LSTM2():\n",
        "  def __init__(self,data,idx):\n",
        "    self.data=data\n",
        "    self.idx=idx\n",
        "    self.time_steps=60\n",
        "\n",
        "  def create_sequences(self, data):\n",
        "    num_samples, num_features = data.shape\n",
        "    sequences = []\n",
        "    for i in range(num_samples - self.time_steps +1):\n",
        "      sequences.append(data[i:i + self.time_steps, :])\n",
        "    return np.array(sequences)\n",
        "\n",
        "  def inverse_sequences(self,data_sequences):\n",
        "    num_samples, num_steps, num_features = data_sequences.shape\n",
        "    data = np.zeros((num_samples + self.time_steps - 1, num_features))\n",
        "    for i in range(num_samples):\n",
        "      data[i:i + self.time_steps, :] += data_sequences[i, :, :]\n",
        "    data /= self.time_steps\n",
        "    return data[:num_samples]\n",
        "    #frquency domain inverse laplace transform\n",
        "\n",
        "  def slicing_data(self):\n",
        "    self.x_scaler = MinMaxScaler()\n",
        "    self.y_scaler = MinMaxScaler()\n",
        "    # Scaling features\n",
        "    x_data = self.data[self.data.columns[:]]\n",
        "    x_data = self.x_scaler.fit_transform(x_data)\n",
        "    # Scaling target variable\n",
        "    y_data = self.data[self.data.columns[:]]\n",
        "    y_data = self.y_scaler.fit_transform(y_data)\n",
        "    # validation set\n",
        "    x_train_p, x_test, y_train_p, y_test = train_test_split(x_data, y_data, test_size=0.8, shuffle=False)\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x_train_p, y_train_p, test_size=0.25, shuffle=False)\n",
        "    __t,x_final,__t,__t=train_test_split(x_data, y_data, test_size=60/len(y_data), shuffle=False)\n",
        "\n",
        "    self.num_features = x_data.shape[1]\n",
        "    self.num_samples=x_data.shape[0]\n",
        "\n",
        "    self.x_train = self.create_sequences(x_train)\n",
        "    self.x_test = self.create_sequences(x_test)\n",
        "    self.x_val = self.create_sequences(x_val)\n",
        "    self.x_final = self.create_sequences(x_final)\n",
        "\n",
        "    self.y_train=self.create_sequences(y_train)\n",
        "    self.y_test=self.create_sequences(y_test)\n",
        "    self.y_val=self.create_sequences(y_val)\n",
        "\n",
        "  def model_struct(self):\n",
        "    self.model = Sequential()\n",
        "    # layers\n",
        "    self.model.add(Bidirectional(LSTM(1024, return_sequences=True, input_shape=(self.time_steps, self.num_features))))\n",
        "    self.model.add(Dense(256, activation='relu'))\n",
        "    self.model.add(Dense(128, activation='relu'))\n",
        "    self.model.add(Dense(64, activation='relu'))\n",
        "    self.model.add(Dense(32, activation='relu'))\n",
        "    self.model.add(Dense(16, activation='relu'))\n",
        "    # output layer (many-to-many with TimeDistributed)\n",
        "    self.model.add(TimeDistributed(Dense(len(self.data.columns), activation='relu')))\n",
        "\n",
        "\n",
        "  def learning(self):\n",
        "    model_save_path = '/content/drive/MyDrive/2023_1st_vac/KRX_modelings/best_model/LSTM2/'\n",
        "\n",
        "    self.filename = join(model_save_path, 'ckeckpointer.ckpt''cke ckpointer_0726_{}.ckpt'.format(self.idx))\n",
        "    checkpoint = ModelCheckpoint(self.filename, save_weights_only=True, save_best_only=True, monitor='val_loss', verbose=0)\n",
        "    earlystopping = EarlyStopping(monitor='val_loss', patience=100)\n",
        "    self.model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.001))\n",
        "    self.history = self.model.fit(self.x_train, self.y_train, epochs=1, batch_size=128, validation_data=(self.x_val, self.y_val), shuffle=False, callbacks=[checkpoint, earlystopping], verbose=0)\n",
        "\n",
        "  def get_gap_by_test(self):\n",
        "    self.model.load_weights(self.filename)\n",
        "    pred = self.model.predict(self.x_test)\n",
        "    rescaled_pred = self.y_scaler.inverse_transform(self.inverse_sequences(pred))\n",
        "    rescaled_real = self.y_scaler.inverse_transform(self.inverse_sequences(self.y_test))\n",
        "\n",
        "    gaps = []\n",
        "\n",
        "    for p, r in zip(rescaled_pred, rescaled_real):\n",
        "        gap = np.abs(p - r)\n",
        "        gaps.append(gap)\n",
        "\n",
        "    avg_gap = np.mean(gaps)\n",
        "\n",
        "\n",
        "    return avg_gap\n",
        "\n",
        "\n",
        "\n",
        "  def return_val(self):\n",
        "      self.slicing_data()\n",
        "      self.model_struct()\n",
        "      self.learning()\n",
        "      self.model.load_weights(self.filename)\n",
        "\n",
        "      next_input_data = np.copy(self.x_final)\n",
        "      for day in range(1, 16):\n",
        "          pred_day = self.model.predict(np.expand_dims(next_input_data[-1], axis=0))\n",
        "          next_input_data = np.concatenate((next_input_data, pred_day), axis=0)\n",
        "\n",
        "      next_15_days_data = next_input_data[-15:]\n",
        "      next_15_days_data=self.y_scaler.inverse_transform(self.inverse_sequences(next_15_days_data))\n",
        "\n",
        "      columns=self.data.columns.tolist()\n",
        "      ret_df = pd.DataFrame(next_15_days_data, columns=columns)\n",
        "\n",
        "      prices=[]\n",
        "      for end_price in ret_df.iloc[:,-2]:\n",
        "        prices.append(end_price)\n",
        "\n",
        "      gap=self.get_gap_by_test()\n",
        "\n",
        "\n",
        "      return prices,gap"
      ],
      "metadata": {
        "id": "bEO6-jiPoMIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TEST **Shell**"
      ],
      "metadata": {
        "id": "Y55lJSg5CtZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l1=[]\n",
        "l2=[]\n",
        "#test shell\n",
        "m=LSTM2(sliced_dataframes[0],0)\n",
        "#m.slicing_data()\n",
        "#m.model_struct()\n",
        "#m.learning()\n",
        "pred,gap1=m.return_val()\n",
        "l1.append(pred)\n",
        "l2.append(gap1)\n",
        "m=LSTM2(sliced_dataframes[1],1)\n",
        "pred1,gap=m.return_val()\n",
        "l1.append(pred1)\n",
        "l2.append(gap)\n",
        "\n",
        "df=pd.DataFrame({\n",
        "    '종가':l1,\n",
        "    'gap':l2\n",
        "})\n",
        "df.to_csv('/content/drive/MyDrive/2023_1st_vac/KRX_modelings/predicitions/{}.csv'.format(\"230725_v0.1\"),index=True)"
      ],
      "metadata": {
        "id": "XXhHclYk_v5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict **Shell**"
      ],
      "metadata": {
        "id": "IE10tBYPCxxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx=0\n",
        "\n",
        "pred_list=[]\n",
        "gap_acc=[]\n",
        "out_labels=[]"
      ],
      "metadata": {
        "id": "7MjKUgGOoK2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for c in sliced_dataframes:\n",
        "  print(labels.iloc[idx])\n",
        "  print(\"{}번째 종목코드\".format(idx))\n",
        "  LSTM_model=LSTM2(c,idx=idx)\n",
        "  pred,gap = LSTM_model.return_val()\n",
        "  sleep(0.5)\n",
        "  pred_list.append(pred)\n",
        "  gap_acc.append(gap)\n",
        "  idx+=1\n",
        "  #to prevent model corrupting"
      ],
      "metadata": {
        "id": "7MgxvelBqH-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_csv_df=pd.DataFrame({\n",
        "    '종목코드':label_lis,\n",
        "    '종가':pred_list,\n",
        "    'gap':gap_acc\n",
        "})"
      ],
      "metadata": {
        "id": "D3zKUPlzI-nY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_csv_df.to_csv('/content/drive/MyDrive/2023_1st_vac/KRX_modelings/predicitions/{}.csv'.format(\"230725_v0.1\"),index=True)"
      ],
      "metadata": {
        "id": "lo5K8wW1HxNm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}