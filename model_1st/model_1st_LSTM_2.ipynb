{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "def getAOC(data):\n",
        "  AOC = []\n",
        "  close = data['종가']\n",
        "\n",
        "  # aoc = (금일 종가 - 전일 종가) / 전일 종가\n",
        "  for i in range(len(close)):\n",
        "    aoc_value = ((close[i] - close[i-1]) / close[i-1]) * 100\n",
        "    if(i % 494 == 0):\n",
        "      aoc_value = 0\n",
        "    AOC.append(aoc_value)\n",
        "\n",
        "  return AOC\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "sub=pd.read_csv(\"./drive/MyDrive/Colab Notebooks/sample_submission.csv\")\n",
        "data=pd.read_csv(\"./drive/MyDrive/Colab Notebooks/train.csv\")\n",
        "\n",
        "#sort data by \"종목명\"\n",
        "subject_Data=data.sort_values(by=\"종목명\",inplace=False)\n",
        "subject_Data.head()\n",
        "subject_Data.columns\n",
        "\n",
        "pv_s_data=pd.pivot_table(subject_Data,values=['거래량', '시가', '고가', '저가', '종가'],index=['종목코드','일자'])\n",
        "\n",
        "pv_s_data[\"AOC\"] = getAOC(pv_s_data)\n",
        "\n",
        "divided = pv_s_data.index.get_level_values('종목코드').unique()\n",
        "\n",
        "sliced_dataframes = []\n",
        "\n",
        "for i in divided:\n",
        "    sliced_data = pv_s_data.loc[i]\n",
        "    sliced_dataframe = sliced_data.reset_index()\n",
        "    sliced_dataframes.append(sliced_dataframe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kxq9kN7I3y_w",
        "outputId": "ee956508-c553-4a56-bd87-8859b034cc95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scale_cols = ['거래량', '고가', '시가', '저가', '종가', 'AOC']\n",
        "scaled = scaler.fit_transform(sliced_dataframes[3][scale_cols])"
      ],
      "metadata": {
        "id": "1F21HHOfdfWj"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(scaled, columns=scale_cols)"
      ],
      "metadata": {
        "id": "2am0lR4ad6nX"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(df.drop('종가', 1), df['종가'], test_size=0.2, random_state=0, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJZq1WRdgJ0a",
        "outputId": "a068b751-1597-484b-8db9-9294b519dcbc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-1202195c6716>:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
            "  x_train, x_test, y_train, y_test = train_test_split(df.drop('종가', 1), df['종가'], test_size=0.2, random_state=0, shuffle=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "def windowed_dataset(series, window_size, batch_size, shuffle):\n",
        "    series = tf.expand_dims(series, axis=-1)\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(1000)\n",
        "    ds = ds.map(lambda w: (w[:-1], w[-1]))\n",
        "    return ds.batch(batch_size).prefetch(1)"
      ],
      "metadata": {
        "id": "eglR9kBDgg9z"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WINDOW_SIZE=20\n",
        "BATCH_SIZE=32\n",
        "\n",
        "# trian_data는 학습용 데이터셋, test_data는 검증용 데이터셋 입니다.\n",
        "train_data = windowed_dataset(y_train, WINDOW_SIZE, BATCH_SIZE, True)\n",
        "test_data = windowed_dataset(y_test, WINDOW_SIZE, BATCH_SIZE, False)\n",
        "\n",
        "# 아래의 코드로 데이터셋의 구성을 확인해 볼 수 있습니다.\n",
        "# X: (batch_size, window_size, feature)\n",
        "# Y: (batch_size, feature)\n",
        "for data in train_data.take(1):\n",
        "    print(f'데이터셋(X) 구성(batch_size, window_size, feature갯수): {data[0].shape}')\n",
        "    print(f'데이터셋(Y) 구성(batch_size, window_size, feature갯수): {data[1].shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GTzp2dEglRi",
        "outputId": "ea36a414-b09f-4519-8764-6a80e7e25b27"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터셋(X) 구성(batch_size, window_size, feature갯수): (32, 20, 1)\n",
            "데이터셋(Y) 구성(batch_size, window_size, feature갯수): (32, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, LSTM, Conv1D, Lambda\n",
        "\n",
        "model = Sequential([\n",
        "    # 1차원 feature map 생성\n",
        "    Conv1D(filters=32, kernel_size=5,\n",
        "           padding=\"causal\",\n",
        "           activation=\"relu\",\n",
        "           input_shape=[WINDOW_SIZE, 1]),\n",
        "    # LSTM\n",
        "    LSTM(16, activation='tanh'),\n",
        "    Dense(16, activation=\"relu\"),\n",
        "    Dense(1),\n",
        "])"
      ],
      "metadata": {
        "id": "rLW4FHKggw9N"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import Huber\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Sequence 학습에 비교적 좋은 퍼포먼스를 내는 Huber()를 사용합니다.\n",
        "loss = Huber()\n",
        "optimizer = Adam(0.0005)\n",
        "model.compile(loss=Huber(), optimizer=optimizer, metrics=['mse'])"
      ],
      "metadata": {
        "id": "qtXCuMVOg6bU"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# earlystopping은 10번 epoch통안 val_loss 개선이 없다면 학습을 멈춥니다.\n",
        "earlystopping = EarlyStopping(monitor='val_loss', patience=50)\n",
        "# val_loss 기준 체크포인터도 생성합니다.\n",
        "filename = os.path.join('tmp', 'ckeckpointer.ckpt')\n",
        "checkpoint = ModelCheckpoint(filename,\n",
        "                             save_weights_only=True,\n",
        "                             save_best_only=True,\n",
        "                             monitor='val_loss',\n",
        "                             verbose=1)"
      ],
      "metadata": {
        "id": "0RqXB65GhDRb"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_data,\n",
        "                    validation_data=(test_data),\n",
        "                    epochs=2000,\n",
        "                    callbacks=[checkpoint, earlystopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOHxFLJZiDme",
        "outputId": "9930d387-f6a0-4d8f-e1ad-19f7cdc14907"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "     11/Unknown - 0s 5ms/step - loss: 0.0019 - mse: 0.0038 \n",
            "Epoch 1: val_loss improved from inf to 0.00129, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0019 - mse: 0.0037 - val_loss: 0.0013 - val_mse: 0.0026\n",
            "Epoch 2/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0018 - mse: 0.0036\n",
            "Epoch 2: val_loss improved from 0.00129 to 0.00120, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 3/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 0.0018 - mse: 0.0036\n",
            "Epoch 3: val_loss improved from 0.00120 to 0.00115, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0018 - mse: 0.0036 - val_loss: 0.0012 - val_mse: 0.0023\n",
            "Epoch 4/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0017 - mse: 0.0034\n",
            "Epoch 4: val_loss did not improve from 0.00115\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0035 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 5/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 0.0017 - mse: 0.0034\n",
            "Epoch 5: val_loss improved from 0.00115 to 0.00106, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0017 - mse: 0.0034 - val_loss: 0.0011 - val_mse: 0.0021\n",
            "Epoch 6/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0018 - mse: 0.0036\n",
            "Epoch 6: val_loss did not improve from 0.00106\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0017 - mse: 0.0035 - val_loss: 0.0012 - val_mse: 0.0024\n",
            "Epoch 7/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 0.0018 - mse: 0.0036\n",
            "Epoch 7: val_loss did not improve from 0.00106\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0017 - mse: 0.0034 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 8/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0017 - mse: 0.0035\n",
            "Epoch 8: val_loss did not improve from 0.00106\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0017 - mse: 0.0034 - val_loss: 0.0012 - val_mse: 0.0023\n",
            "Epoch 9/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 0.0018 - mse: 0.0035\n",
            "Epoch 9: val_loss did not improve from 0.00106\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0017 - mse: 0.0034 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 10/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 0.0017 - mse: 0.0034\n",
            "Epoch 10: val_loss improved from 0.00106 to 0.00104, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0017 - mse: 0.0034 - val_loss: 0.0010 - val_mse: 0.0021\n",
            "Epoch 11/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 0.0017 - mse: 0.0034\n",
            "Epoch 11: val_loss did not improve from 0.00104\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0017 - mse: 0.0033 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 12/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 0.0019 - mse: 0.0037    \n",
            "Epoch 12: val_loss did not improve from 0.00104\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0017 - mse: 0.0033 - val_loss: 0.0011 - val_mse: 0.0021\n",
            "Epoch 13/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 0.0016 - mse: 0.0033\n",
            "Epoch 13: val_loss improved from 0.00104 to 0.00103, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0016 - mse: 0.0033 - val_loss: 0.0010 - val_mse: 0.0021\n",
            "Epoch 14/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 0.0016 - mse: 0.0031\n",
            "Epoch 14: val_loss improved from 0.00103 to 0.00100, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 0.0010 - val_mse: 0.0020\n",
            "Epoch 15/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 0.0016 - mse: 0.0032\n",
            "Epoch 15: val_loss improved from 0.00100 to 0.00099, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 9.8932e-04 - val_mse: 0.0020\n",
            "Epoch 16/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0015 - mse: 0.0030    \n",
            "Epoch 16: val_loss did not improve from 0.00099\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 0.0010 - val_mse: 0.0020\n",
            "Epoch 17/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0017 - mse: 0.0033    \n",
            "Epoch 17: val_loss did not improve from 0.00099\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0016 - mse: 0.0032 - val_loss: 0.0010 - val_mse: 0.0021\n",
            "Epoch 18/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 0.0017 - mse: 0.0035\n",
            "Epoch 18: val_loss improved from 0.00099 to 0.00091, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0017 - mse: 0.0033 - val_loss: 9.1198e-04 - val_mse: 0.0018\n",
            "Epoch 19/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 0.0015 - mse: 0.0031\n",
            "Epoch 19: val_loss did not improve from 0.00091\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0015 - mse: 0.0031 - val_loss: 0.0010 - val_mse: 0.0021\n",
            "Epoch 20/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 0.0012 - mse: 0.0025    \n",
            "Epoch 20: val_loss improved from 0.00091 to 0.00088, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 8.8310e-04 - val_mse: 0.0018\n",
            "Epoch 21/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 0.0016 - mse: 0.0033\n",
            "Epoch 21: val_loss did not improve from 0.00088\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0031 - val_loss: 0.0010 - val_mse: 0.0020\n",
            "Epoch 22/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 0.0016 - mse: 0.0031    \n",
            "Epoch 22: val_loss did not improve from 0.00088\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0031 - val_loss: 9.1050e-04 - val_mse: 0.0018\n",
            "Epoch 23/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0015 - mse: 0.0030\n",
            "Epoch 23: val_loss did not improve from 0.00088\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 9.8158e-04 - val_mse: 0.0020\n",
            "Epoch 24/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 0.0015 - mse: 0.0031    \n",
            "Epoch 24: val_loss did not improve from 0.00088\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 9.8243e-04 - val_mse: 0.0020\n",
            "Epoch 25/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0014 - mse: 0.0029\n",
            "Epoch 25: val_loss improved from 0.00088 to 0.00083, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0015 - mse: 0.0029 - val_loss: 8.3479e-04 - val_mse: 0.0017\n",
            "Epoch 26/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0016 - mse: 0.0031\n",
            "Epoch 26: val_loss did not improve from 0.00083\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 0.0011 - val_mse: 0.0021\n",
            "Epoch 27/2000\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.0015 - mse: 0.0029    \n",
            "Epoch 27: val_loss improved from 0.00083 to 0.00082, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0015 - mse: 0.0029 - val_loss: 8.2406e-04 - val_mse: 0.0016\n",
            "Epoch 28/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0015 - mse: 0.0029\n",
            "Epoch 28: val_loss did not improve from 0.00082\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 0.0011 - val_mse: 0.0022\n",
            "Epoch 29/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0014 - mse: 0.0029\n",
            "Epoch 29: val_loss improved from 0.00082 to 0.00078, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 7.8449e-04 - val_mse: 0.0016\n",
            "Epoch 30/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 30: val_loss did not improve from 0.00078\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 8.4058e-04 - val_mse: 0.0017\n",
            "Epoch 31/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 0.0014 - mse: 0.0028    \n",
            "Epoch 31: val_loss did not improve from 0.00078\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0015 - mse: 0.0029 - val_loss: 0.0010 - val_mse: 0.0020\n",
            "Epoch 32/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0015 - mse: 0.0029\n",
            "Epoch 32: val_loss did not improve from 0.00078\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0029 - val_loss: 8.7072e-04 - val_mse: 0.0017\n",
            "Epoch 33/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 0.0015 - mse: 0.0030\n",
            "Epoch 33: val_loss did not improve from 0.00078\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0014 - mse: 0.0028 - val_loss: 8.0876e-04 - val_mse: 0.0016\n",
            "Epoch 34/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0014 - mse: 0.0028\n",
            "Epoch 34: val_loss did not improve from 0.00078\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 8.2899e-04 - val_mse: 0.0017\n",
            "Epoch 35/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0013 - mse: 0.0027\n",
            "Epoch 35: val_loss did not improve from 0.00078\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 9.4386e-04 - val_mse: 0.0019\n",
            "Epoch 36/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 0.0015 - mse: 0.0030\n",
            "Epoch 36: val_loss improved from 0.00078 to 0.00072, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 7.1906e-04 - val_mse: 0.0014\n",
            "Epoch 37/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0013 - mse: 0.0027    \n",
            "Epoch 37: val_loss did not improve from 0.00072\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0014 - mse: 0.0027 - val_loss: 8.6030e-04 - val_mse: 0.0017\n",
            "Epoch 38/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 0.0013 - mse: 0.0026\n",
            "Epoch 38: val_loss did not improve from 0.00072\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0013 - mse: 0.0026 - val_loss: 8.4497e-04 - val_mse: 0.0017\n",
            "Epoch 39/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 39: val_loss did not improve from 0.00072\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 7.2417e-04 - val_mse: 0.0014\n",
            "Epoch 40/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0012 - mse: 0.0025    \n",
            "Epoch 40: val_loss did not improve from 0.00072\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0013 - mse: 0.0025 - val_loss: 8.2807e-04 - val_mse: 0.0017\n",
            "Epoch 41/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0013 - mse: 0.0026\n",
            "Epoch 41: val_loss did not improve from 0.00072\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 7.5072e-04 - val_mse: 0.0015\n",
            "Epoch 42/2000\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.0012 - mse: 0.0025    \n",
            "Epoch 42: val_loss did not improve from 0.00072\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 7.6778e-04 - val_mse: 0.0015\n",
            "Epoch 43/2000\n",
            " 6/12 [==============>...............] - ETA: 0s - loss: 0.0010 - mse: 0.0020    \n",
            "Epoch 43: val_loss did not improve from 0.00072\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 7.9618e-04 - val_mse: 0.0016\n",
            "Epoch 44/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 0.0012 - mse: 0.0025    \n",
            "Epoch 44: val_loss improved from 0.00072 to 0.00071, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 7.0572e-04 - val_mse: 0.0014\n",
            "Epoch 45/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 0.0014 - mse: 0.0027    \n",
            "Epoch 45: val_loss did not improve from 0.00071\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 9.2550e-04 - val_mse: 0.0019\n",
            "Epoch 46/2000\n",
            " 6/12 [==============>...............] - ETA: 0s - loss: 0.0013 - mse: 0.0026\n",
            "Epoch 46: val_loss improved from 0.00071 to 0.00065, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0012 - mse: 0.0025 - val_loss: 6.5381e-04 - val_mse: 0.0013\n",
            "Epoch 47/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0012 - mse: 0.0024\n",
            "Epoch 47: val_loss did not improve from 0.00065\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 7.9023e-04 - val_mse: 0.0016\n",
            "Epoch 48/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 0.0011 - mse: 0.0021    \n",
            "Epoch 48: val_loss did not improve from 0.00065\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - mse: 0.0023 - val_loss: 6.5802e-04 - val_mse: 0.0013\n",
            "Epoch 49/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0011 - mse: 0.0023\n",
            "Epoch 49: val_loss did not improve from 0.00065\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0023 - val_loss: 7.5425e-04 - val_mse: 0.0015\n",
            "Epoch 50/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 0.0012 - mse: 0.0025\n",
            "Epoch 50: val_loss did not improve from 0.00065\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 8.6807e-04 - val_mse: 0.0017\n",
            "Epoch 51/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 0.0013 - mse: 0.0025\n",
            "Epoch 51: val_loss did not improve from 0.00065\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 7.4735e-04 - val_mse: 0.0015\n",
            "Epoch 52/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 0.0011 - mse: 0.0023\n",
            "Epoch 52: val_loss did not improve from 0.00065\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 6.9009e-04 - val_mse: 0.0014\n",
            "Epoch 53/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 0.0011 - mse: 0.0023    \n",
            "Epoch 53: val_loss improved from 0.00065 to 0.00064, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 6.3994e-04 - val_mse: 0.0013\n",
            "Epoch 54/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0011 - mse: 0.0022\n",
            "Epoch 54: val_loss improved from 0.00064 to 0.00063, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 6.2708e-04 - val_mse: 0.0013\n",
            "Epoch 55/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0010 - mse: 0.0020    \n",
            "Epoch 55: val_loss improved from 0.00063 to 0.00060, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 5.9680e-04 - val_mse: 0.0012\n",
            "Epoch 56/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 0.0010 - mse: 0.0021    \n",
            "Epoch 56: val_loss did not improve from 0.00060\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - mse: 0.0021 - val_loss: 7.1025e-04 - val_mse: 0.0014\n",
            "Epoch 57/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 0.0010 - mse: 0.0020\n",
            "Epoch 57: val_loss did not improve from 0.00060\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 6.6121e-04 - val_mse: 0.0013\n",
            "Epoch 58/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 9.7387e-04 - mse: 0.0019\n",
            "Epoch 58: val_loss did not improve from 0.00060\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0010 - mse: 0.0020 - val_loss: 6.6761e-04 - val_mse: 0.0013\n",
            "Epoch 59/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.0010 - mse: 0.0020    \n",
            "Epoch 59: val_loss improved from 0.00060 to 0.00059, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 9.9384e-04 - mse: 0.0020 - val_loss: 5.8712e-04 - val_mse: 0.0012\n",
            "Epoch 60/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 9.2906e-04 - mse: 0.0019\n",
            "Epoch 60: val_loss did not improve from 0.00059\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 9.8386e-04 - mse: 0.0020 - val_loss: 6.1917e-04 - val_mse: 0.0012\n",
            "Epoch 61/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 9.4479e-04 - mse: 0.0019\n",
            "Epoch 61: val_loss did not improve from 0.00059\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 9.5723e-04 - mse: 0.0019 - val_loss: 6.2707e-04 - val_mse: 0.0013\n",
            "Epoch 62/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 9.4291e-04 - mse: 0.0019\n",
            "Epoch 62: val_loss did not improve from 0.00059\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 9.5608e-04 - mse: 0.0019 - val_loss: 6.2828e-04 - val_mse: 0.0013\n",
            "Epoch 63/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 9.3188e-04 - mse: 0.0019\n",
            "Epoch 63: val_loss did not improve from 0.00059\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 9.5536e-04 - mse: 0.0019 - val_loss: 6.2711e-04 - val_mse: 0.0013\n",
            "Epoch 64/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 9.8782e-04 - mse: 0.0020\n",
            "Epoch 64: val_loss did not improve from 0.00059\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 9.5416e-04 - mse: 0.0019 - val_loss: 5.9897e-04 - val_mse: 0.0012\n",
            "Epoch 65/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 8.2307e-04 - mse: 0.0016\n",
            "Epoch 65: val_loss improved from 0.00059 to 0.00058, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 9.1263e-04 - mse: 0.0018 - val_loss: 5.7696e-04 - val_mse: 0.0012\n",
            "Epoch 66/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 8.4832e-04 - mse: 0.0017\n",
            "Epoch 66: val_loss improved from 0.00058 to 0.00052, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.9781e-04 - mse: 0.0018 - val_loss: 5.1814e-04 - val_mse: 0.0010\n",
            "Epoch 67/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 0.0010 - mse: 0.0020\n",
            "Epoch 67: val_loss did not improve from 0.00052\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 9.4701e-04 - mse: 0.0019 - val_loss: 6.1384e-04 - val_mse: 0.0012\n",
            "Epoch 68/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 8.9520e-04 - mse: 0.0018\n",
            "Epoch 68: val_loss did not improve from 0.00052\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 8.7656e-04 - mse: 0.0018 - val_loss: 5.6888e-04 - val_mse: 0.0011\n",
            "Epoch 69/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 8.5822e-04 - mse: 0.0017\n",
            "Epoch 69: val_loss improved from 0.00052 to 0.00052, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.7407e-04 - mse: 0.0017 - val_loss: 5.1755e-04 - val_mse: 0.0010\n",
            "Epoch 70/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 8.1397e-04 - mse: 0.0016\n",
            "Epoch 70: val_loss improved from 0.00052 to 0.00051, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.9660e-04 - mse: 0.0018 - val_loss: 5.0910e-04 - val_mse: 0.0010\n",
            "Epoch 71/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 9.3049e-04 - mse: 0.0019\n",
            "Epoch 71: val_loss did not improve from 0.00051\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 8.9406e-04 - mse: 0.0018 - val_loss: 5.8078e-04 - val_mse: 0.0012\n",
            "Epoch 72/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 8.4844e-04 - mse: 0.0017\n",
            "Epoch 72: val_loss did not improve from 0.00051\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2928e-04 - mse: 0.0017 - val_loss: 5.2090e-04 - val_mse: 0.0010\n",
            "Epoch 73/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 8.3753e-04 - mse: 0.0017\n",
            "Epoch 73: val_loss did not improve from 0.00051\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2158e-04 - mse: 0.0016 - val_loss: 5.6986e-04 - val_mse: 0.0011\n",
            "Epoch 74/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 8.6209e-04 - mse: 0.0017\n",
            "Epoch 74: val_loss did not improve from 0.00051\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2449e-04 - mse: 0.0016 - val_loss: 5.3026e-04 - val_mse: 0.0011\n",
            "Epoch 75/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 8.0796e-04 - mse: 0.0016\n",
            "Epoch 75: val_loss improved from 0.00051 to 0.00049, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 8.0305e-04 - mse: 0.0016 - val_loss: 4.8703e-04 - val_mse: 9.7406e-04\n",
            "Epoch 76/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 8.5308e-04 - mse: 0.0017\n",
            "Epoch 76: val_loss improved from 0.00049 to 0.00047, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.1395e-04 - mse: 0.0016 - val_loss: 4.7307e-04 - val_mse: 9.4614e-04\n",
            "Epoch 77/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 8.3307e-04 - mse: 0.0017\n",
            "Epoch 77: val_loss did not improve from 0.00047\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 8.0447e-04 - mse: 0.0016 - val_loss: 5.0254e-04 - val_mse: 0.0010\n",
            "Epoch 78/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 7.5896e-04 - mse: 0.0015\n",
            "Epoch 78: val_loss did not improve from 0.00047\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 7.8224e-04 - mse: 0.0016 - val_loss: 5.3625e-04 - val_mse: 0.0011\n",
            "Epoch 79/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 7.8317e-04 - mse: 0.0016\n",
            "Epoch 79: val_loss did not improve from 0.00047\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 7.6390e-04 - mse: 0.0015 - val_loss: 4.7895e-04 - val_mse: 9.5790e-04\n",
            "Epoch 80/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 7.3732e-04 - mse: 0.0015\n",
            "Epoch 80: val_loss improved from 0.00047 to 0.00045, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 7.7695e-04 - mse: 0.0016 - val_loss: 4.5385e-04 - val_mse: 9.0770e-04\n",
            "Epoch 81/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 8.0085e-04 - mse: 0.0016\n",
            "Epoch 81: val_loss did not improve from 0.00045\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 7.7179e-04 - mse: 0.0015 - val_loss: 5.1165e-04 - val_mse: 0.0010\n",
            "Epoch 82/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 7.2970e-04 - mse: 0.0015\n",
            "Epoch 82: val_loss did not improve from 0.00045\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 8.2142e-04 - mse: 0.0016 - val_loss: 4.9536e-04 - val_mse: 9.9071e-04\n",
            "Epoch 83/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 7.6769e-04 - mse: 0.0015\n",
            "Epoch 83: val_loss did not improve from 0.00045\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 7.4927e-04 - mse: 0.0015 - val_loss: 5.0228e-04 - val_mse: 0.0010\n",
            "Epoch 84/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 7.2301e-04 - mse: 0.0014\n",
            "Epoch 84: val_loss did not improve from 0.00045\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 7.2932e-04 - mse: 0.0015 - val_loss: 4.9153e-04 - val_mse: 9.8306e-04\n",
            "Epoch 85/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 6.9620e-04 - mse: 0.0014    \n",
            "Epoch 85: val_loss improved from 0.00045 to 0.00043, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 7.0713e-04 - mse: 0.0014 - val_loss: 4.3220e-04 - val_mse: 8.6441e-04\n",
            "Epoch 86/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 7.0526e-04 - mse: 0.0014\n",
            "Epoch 86: val_loss did not improve from 0.00043\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 7.0508e-04 - mse: 0.0014 - val_loss: 4.8329e-04 - val_mse: 9.6658e-04\n",
            "Epoch 87/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 6.8926e-04 - mse: 0.0014\n",
            "Epoch 87: val_loss did not improve from 0.00043\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 6.9374e-04 - mse: 0.0014 - val_loss: 4.4533e-04 - val_mse: 8.9066e-04\n",
            "Epoch 88/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 5.7866e-04 - mse: 0.0012    \n",
            "Epoch 88: val_loss improved from 0.00043 to 0.00041, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 6.7763e-04 - mse: 0.0014 - val_loss: 4.1060e-04 - val_mse: 8.2120e-04\n",
            "Epoch 89/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 7.7579e-04 - mse: 0.0016\n",
            "Epoch 89: val_loss did not improve from 0.00041\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 8.6643e-04 - mse: 0.0017 - val_loss: 4.2987e-04 - val_mse: 8.5974e-04\n",
            "Epoch 90/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 6.7128e-04 - mse: 0.0013\n",
            "Epoch 90: val_loss did not improve from 0.00041\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 7.0549e-04 - mse: 0.0014 - val_loss: 4.6484e-04 - val_mse: 9.2968e-04\n",
            "Epoch 91/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 6.7439e-04 - mse: 0.0013    \n",
            "Epoch 91: val_loss did not improve from 0.00041\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 6.9388e-04 - mse: 0.0014 - val_loss: 5.1422e-04 - val_mse: 0.0010\n",
            "Epoch 92/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 5.6992e-04 - mse: 0.0011    \n",
            "Epoch 92: val_loss did not improve from 0.00041\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 7.2208e-04 - mse: 0.0014 - val_loss: 4.1508e-04 - val_mse: 8.3015e-04\n",
            "Epoch 93/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 7.0196e-04 - mse: 0.0014\n",
            "Epoch 93: val_loss improved from 0.00041 to 0.00039, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 7.2434e-04 - mse: 0.0014 - val_loss: 3.9429e-04 - val_mse: 7.8859e-04\n",
            "Epoch 94/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 6.2944e-04 - mse: 0.0013\n",
            "Epoch 94: val_loss did not improve from 0.00039\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 6.5319e-04 - mse: 0.0013 - val_loss: 4.3539e-04 - val_mse: 8.7078e-04\n",
            "Epoch 95/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 5.7207e-04 - mse: 0.0011    \n",
            "Epoch 95: val_loss did not improve from 0.00039\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 6.6860e-04 - mse: 0.0013 - val_loss: 4.5941e-04 - val_mse: 9.1882e-04\n",
            "Epoch 96/2000\n",
            "12/12 [==============================] - ETA: 0s - loss: 6.4626e-04 - mse: 0.0013\n",
            "Epoch 96: val_loss did not improve from 0.00039\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 6.4626e-04 - mse: 0.0013 - val_loss: 4.1039e-04 - val_mse: 8.2077e-04\n",
            "Epoch 97/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 6.1993e-04 - mse: 0.0012\n",
            "Epoch 97: val_loss did not improve from 0.00039\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 6.3714e-04 - mse: 0.0013 - val_loss: 4.4022e-04 - val_mse: 8.8045e-04\n",
            "Epoch 98/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 8.0073e-04 - mse: 0.0016    \n",
            "Epoch 98: val_loss did not improve from 0.00039\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 6.4011e-04 - mse: 0.0013 - val_loss: 4.8114e-04 - val_mse: 9.6229e-04\n",
            "Epoch 99/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 7.5505e-04 - mse: 0.0015    \n",
            "Epoch 99: val_loss did not improve from 0.00039\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 6.9985e-04 - mse: 0.0014 - val_loss: 4.1996e-04 - val_mse: 8.3991e-04\n",
            "Epoch 100/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 6.0115e-04 - mse: 0.0012\n",
            "Epoch 100: val_loss did not improve from 0.00039\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 6.1802e-04 - mse: 0.0012 - val_loss: 4.0197e-04 - val_mse: 8.0394e-04\n",
            "Epoch 101/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 6.2234e-04 - mse: 0.0012\n",
            "Epoch 101: val_loss improved from 0.00039 to 0.00037, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.2294e-04 - mse: 0.0012 - val_loss: 3.6895e-04 - val_mse: 7.3790e-04\n",
            "Epoch 102/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 5.9553e-04 - mse: 0.0012\n",
            "Epoch 102: val_loss did not improve from 0.00037\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.9803e-04 - mse: 0.0012 - val_loss: 4.3949e-04 - val_mse: 8.7897e-04\n",
            "Epoch 103/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 6.4276e-04 - mse: 0.0013\n",
            "Epoch 103: val_loss did not improve from 0.00037\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 6.0631e-04 - mse: 0.0012 - val_loss: 4.1163e-04 - val_mse: 8.2325e-04\n",
            "Epoch 104/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 6.0275e-04 - mse: 0.0012    \n",
            "Epoch 104: val_loss improved from 0.00037 to 0.00036, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 6.2175e-04 - mse: 0.0012 - val_loss: 3.5892e-04 - val_mse: 7.1784e-04\n",
            "Epoch 105/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 6.3369e-04 - mse: 0.0013    \n",
            "Epoch 105: val_loss did not improve from 0.00036\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 6.4735e-04 - mse: 0.0013 - val_loss: 3.5998e-04 - val_mse: 7.1997e-04\n",
            "Epoch 106/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 5.9800e-04 - mse: 0.0012\n",
            "Epoch 106: val_loss did not improve from 0.00036\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 5.9305e-04 - mse: 0.0012 - val_loss: 4.1631e-04 - val_mse: 8.3263e-04\n",
            "Epoch 107/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 6.2552e-04 - mse: 0.0013\n",
            "Epoch 107: val_loss did not improve from 0.00036\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 5.9904e-04 - mse: 0.0012 - val_loss: 4.2132e-04 - val_mse: 8.4264e-04\n",
            "Epoch 108/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 5.6004e-04 - mse: 0.0011\n",
            "Epoch 108: val_loss did not improve from 0.00036\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 6.0958e-04 - mse: 0.0012 - val_loss: 3.6845e-04 - val_mse: 7.3691e-04\n",
            "Epoch 109/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 5.8373e-04 - mse: 0.0012\n",
            "Epoch 109: val_loss did not improve from 0.00036\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.6912e-04 - mse: 0.0011 - val_loss: 4.3829e-04 - val_mse: 8.7657e-04\n",
            "Epoch 110/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 6.1835e-04 - mse: 0.0012    \n",
            "Epoch 110: val_loss did not improve from 0.00036\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 6.0191e-04 - mse: 0.0012 - val_loss: 4.1084e-04 - val_mse: 8.2169e-04\n",
            "Epoch 111/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 5.8425e-04 - mse: 0.0012\n",
            "Epoch 111: val_loss did not improve from 0.00036\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 5.9498e-04 - mse: 0.0012 - val_loss: 3.6697e-04 - val_mse: 7.3393e-04\n",
            "Epoch 112/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 6.0896e-04 - mse: 0.0012\n",
            "Epoch 112: val_loss did not improve from 0.00036\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 5.5709e-04 - mse: 0.0011 - val_loss: 3.8464e-04 - val_mse: 7.6928e-04\n",
            "Epoch 113/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 5.8064e-04 - mse: 0.0012    \n",
            "Epoch 113: val_loss did not improve from 0.00036\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.6646e-04 - mse: 0.0011 - val_loss: 3.9947e-04 - val_mse: 7.9894e-04\n",
            "Epoch 114/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 5.6955e-04 - mse: 0.0011\n",
            "Epoch 114: val_loss improved from 0.00036 to 0.00034, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 6.3340e-04 - mse: 0.0013 - val_loss: 3.4303e-04 - val_mse: 6.8606e-04\n",
            "Epoch 115/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 6.2930e-04 - mse: 0.0013    \n",
            "Epoch 115: val_loss did not improve from 0.00034\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 6.7819e-04 - mse: 0.0014 - val_loss: 5.4848e-04 - val_mse: 0.0011\n",
            "Epoch 116/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 6.2375e-04 - mse: 0.0012\n",
            "Epoch 116: val_loss did not improve from 0.00034\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 6.1905e-04 - mse: 0.0012 - val_loss: 4.3995e-04 - val_mse: 8.7990e-04\n",
            "Epoch 117/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 6.0504e-04 - mse: 0.0012\n",
            "Epoch 117: val_loss did not improve from 0.00034\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 6.0781e-04 - mse: 0.0012 - val_loss: 3.8323e-04 - val_mse: 7.6646e-04\n",
            "Epoch 118/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 5.5837e-04 - mse: 0.0011\n",
            "Epoch 118: val_loss did not improve from 0.00034\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 5.6477e-04 - mse: 0.0011 - val_loss: 3.6196e-04 - val_mse: 7.2392e-04\n",
            "Epoch 119/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.4968e-04 - mse: 8.9935e-04\n",
            "Epoch 119: val_loss did not improve from 0.00034\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 5.5147e-04 - mse: 0.0011 - val_loss: 3.5913e-04 - val_mse: 7.1825e-04\n",
            "Epoch 120/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.9880e-04 - mse: 9.9759e-04\n",
            "Epoch 120: val_loss did not improve from 0.00034\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.4059e-04 - mse: 0.0011 - val_loss: 3.6949e-04 - val_mse: 7.3899e-04\n",
            "Epoch 121/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 5.7062e-04 - mse: 0.0011\n",
            "Epoch 121: val_loss did not improve from 0.00034\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.6600e-04 - mse: 0.0011 - val_loss: 4.7203e-04 - val_mse: 9.4405e-04\n",
            "Epoch 122/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 6.5306e-04 - mse: 0.0013\n",
            "Epoch 122: val_loss did not improve from 0.00034\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 6.3407e-04 - mse: 0.0013 - val_loss: 4.8172e-04 - val_mse: 9.6343e-04\n",
            "Epoch 123/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 5.9631e-04 - mse: 0.0012    \n",
            "Epoch 123: val_loss did not improve from 0.00034\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 5.8322e-04 - mse: 0.0012 - val_loss: 3.5037e-04 - val_mse: 7.0074e-04\n",
            "Epoch 124/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 5.6261e-04 - mse: 0.0011    \n",
            "Epoch 124: val_loss improved from 0.00034 to 0.00034, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 5.4775e-04 - mse: 0.0011 - val_loss: 3.4097e-04 - val_mse: 6.8195e-04\n",
            "Epoch 125/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 6.0721e-04 - mse: 0.0012\n",
            "Epoch 125: val_loss improved from 0.00034 to 0.00031, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 5.7837e-04 - mse: 0.0012 - val_loss: 3.0658e-04 - val_mse: 6.1316e-04\n",
            "Epoch 126/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 5.7824e-04 - mse: 0.0012\n",
            "Epoch 126: val_loss improved from 0.00031 to 0.00030, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 5.7368e-04 - mse: 0.0011 - val_loss: 3.0309e-04 - val_mse: 6.0618e-04\n",
            "Epoch 127/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 5.8138e-04 - mse: 0.0012    \n",
            "Epoch 127: val_loss did not improve from 0.00030\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 5.6597e-04 - mse: 0.0011 - val_loss: 3.2253e-04 - val_mse: 6.4505e-04\n",
            "Epoch 128/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 5.8288e-04 - mse: 0.0012    \n",
            "Epoch 128: val_loss did not improve from 0.00030\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 5.4213e-04 - mse: 0.0011 - val_loss: 3.8735e-04 - val_mse: 7.7470e-04\n",
            "Epoch 129/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 6.0525e-04 - mse: 0.0012\n",
            "Epoch 129: val_loss did not improve from 0.00030\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 5.3506e-04 - mse: 0.0011 - val_loss: 3.1988e-04 - val_mse: 6.3976e-04\n",
            "Epoch 130/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 5.1342e-04 - mse: 0.0010\n",
            "Epoch 130: val_loss did not improve from 0.00030\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.2108e-04 - mse: 0.0010 - val_loss: 3.6119e-04 - val_mse: 7.2238e-04\n",
            "Epoch 131/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 4.9276e-04 - mse: 9.8552e-04\n",
            "Epoch 131: val_loss did not improve from 0.00030\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 5.1930e-04 - mse: 0.0010 - val_loss: 4.0613e-04 - val_mse: 8.1227e-04\n",
            "Epoch 132/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 5.3364e-04 - mse: 0.0011\n",
            "Epoch 132: val_loss did not improve from 0.00030\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 5.3054e-04 - mse: 0.0011 - val_loss: 3.4988e-04 - val_mse: 6.9977e-04\n",
            "Epoch 133/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 5.5183e-04 - mse: 0.0011    \n",
            "Epoch 133: val_loss improved from 0.00030 to 0.00030, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 5.3570e-04 - mse: 0.0011 - val_loss: 3.0059e-04 - val_mse: 6.0117e-04\n",
            "Epoch 134/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 5.0817e-04 - mse: 0.0010    \n",
            "Epoch 134: val_loss improved from 0.00030 to 0.00030, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 5.1441e-04 - mse: 0.0010 - val_loss: 2.9540e-04 - val_mse: 5.9079e-04\n",
            "Epoch 135/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 4.9868e-04 - mse: 9.9737e-04\n",
            "Epoch 135: val_loss did not improve from 0.00030\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.0143e-04 - mse: 0.0010 - val_loss: 3.1617e-04 - val_mse: 6.3235e-04\n",
            "Epoch 136/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.5650e-04 - mse: 9.1301e-04\n",
            "Epoch 136: val_loss did not improve from 0.00030\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.9703e-04 - mse: 9.9406e-04 - val_loss: 3.3565e-04 - val_mse: 6.7131e-04\n",
            "Epoch 137/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 5.5181e-04 - mse: 0.0011\n",
            "Epoch 137: val_loss did not improve from 0.00030\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 5.1971e-04 - mse: 0.0010 - val_loss: 2.9956e-04 - val_mse: 5.9912e-04\n",
            "Epoch 138/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.5540e-04 - mse: 9.1079e-04\n",
            "Epoch 138: val_loss did not improve from 0.00030\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.9653e-04 - mse: 9.9305e-04 - val_loss: 3.3445e-04 - val_mse: 6.6890e-04\n",
            "Epoch 139/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 5.3652e-04 - mse: 0.0011    \n",
            "Epoch 139: val_loss did not improve from 0.00030\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.0941e-04 - mse: 0.0010 - val_loss: 3.5011e-04 - val_mse: 7.0023e-04\n",
            "Epoch 140/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 5.1084e-04 - mse: 0.0010\n",
            "Epoch 140: val_loss did not improve from 0.00030\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.0062e-04 - mse: 0.0010 - val_loss: 3.4102e-04 - val_mse: 6.8204e-04\n",
            "Epoch 141/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 6.3885e-04 - mse: 0.0013\n",
            "Epoch 141: val_loss did not improve from 0.00030\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 5.7782e-04 - mse: 0.0012 - val_loss: 3.3516e-04 - val_mse: 6.7032e-04\n",
            "Epoch 142/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 5.1157e-04 - mse: 0.0010    \n",
            "Epoch 142: val_loss did not improve from 0.00030\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.2014e-04 - mse: 0.0010 - val_loss: 3.3704e-04 - val_mse: 6.7408e-04\n",
            "Epoch 143/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 5.2439e-04 - mse: 0.0010\n",
            "Epoch 143: val_loss improved from 0.00030 to 0.00027, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 5.0211e-04 - mse: 0.0010 - val_loss: 2.7013e-04 - val_mse: 5.4025e-04\n",
            "Epoch 144/2000\n",
            " 6/12 [==============>...............] - ETA: 0s - loss: 5.9589e-04 - mse: 0.0012\n",
            "Epoch 144: val_loss did not improve from 0.00027\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 5.2388e-04 - mse: 0.0010 - val_loss: 2.7224e-04 - val_mse: 5.4448e-04\n",
            "Epoch 145/2000\n",
            "12/12 [==============================] - ETA: 0s - loss: 5.2985e-04 - mse: 0.0011    \n",
            "Epoch 145: val_loss did not improve from 0.00027\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 5.2985e-04 - mse: 0.0011 - val_loss: 2.9425e-04 - val_mse: 5.8850e-04\n",
            "Epoch 146/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 4.9192e-04 - mse: 9.8385e-04\n",
            "Epoch 146: val_loss did not improve from 0.00027\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 5.0880e-04 - mse: 0.0010 - val_loss: 2.8188e-04 - val_mse: 5.6375e-04\n",
            "Epoch 147/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 4.3024e-04 - mse: 8.6049e-04\n",
            "Epoch 147: val_loss did not improve from 0.00027\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 5.2254e-04 - mse: 0.0010 - val_loss: 2.9185e-04 - val_mse: 5.8370e-04\n",
            "Epoch 148/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 5.2460e-04 - mse: 0.0010    \n",
            "Epoch 148: val_loss improved from 0.00027 to 0.00026, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 5.3977e-04 - mse: 0.0011 - val_loss: 2.6126e-04 - val_mse: 5.2252e-04\n",
            "Epoch 149/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 5.1507e-04 - mse: 0.0010    \n",
            "Epoch 149: val_loss did not improve from 0.00026\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 5.2491e-04 - mse: 0.0010 - val_loss: 2.7011e-04 - val_mse: 5.4023e-04\n",
            "Epoch 150/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 5.6299e-04 - mse: 0.0011    \n",
            "Epoch 150: val_loss did not improve from 0.00026\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 5.1415e-04 - mse: 0.0010 - val_loss: 2.9268e-04 - val_mse: 5.8537e-04\n",
            "Epoch 151/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 5.7624e-04 - mse: 0.0012\n",
            "Epoch 151: val_loss did not improve from 0.00026\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 5.2081e-04 - mse: 0.0010 - val_loss: 2.6899e-04 - val_mse: 5.3798e-04\n",
            "Epoch 152/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 5.4849e-04 - mse: 0.0011\n",
            "Epoch 152: val_loss improved from 0.00026 to 0.00026, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 5.7341e-04 - mse: 0.0011 - val_loss: 2.5699e-04 - val_mse: 5.1399e-04\n",
            "Epoch 153/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 6.6954e-04 - mse: 0.0013\n",
            "Epoch 153: val_loss did not improve from 0.00026\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 5.9433e-04 - mse: 0.0012 - val_loss: 2.5893e-04 - val_mse: 5.1786e-04\n",
            "Epoch 154/2000\n",
            " 6/12 [==============>...............] - ETA: 0s - loss: 6.4487e-04 - mse: 0.0013\n",
            "Epoch 154: val_loss did not improve from 0.00026\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 5.5513e-04 - mse: 0.0011 - val_loss: 2.7850e-04 - val_mse: 5.5699e-04\n",
            "Epoch 155/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 5.0225e-04 - mse: 0.0010\n",
            "Epoch 155: val_loss improved from 0.00026 to 0.00025, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 4.8740e-04 - mse: 9.7480e-04 - val_loss: 2.5435e-04 - val_mse: 5.0870e-04\n",
            "Epoch 156/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.8773e-04 - mse: 9.7545e-04\n",
            "Epoch 156: val_loss did not improve from 0.00025\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.9120e-04 - mse: 9.8241e-04 - val_loss: 2.9668e-04 - val_mse: 5.9335e-04\n",
            "Epoch 157/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 5.0127e-04 - mse: 0.0010    \n",
            "Epoch 157: val_loss did not improve from 0.00025\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.8631e-04 - mse: 9.7262e-04 - val_loss: 3.0331e-04 - val_mse: 6.0662e-04\n",
            "Epoch 158/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.8154e-04 - mse: 9.6308e-04\n",
            "Epoch 158: val_loss improved from 0.00025 to 0.00025, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 4.6990e-04 - mse: 9.3980e-04 - val_loss: 2.4910e-04 - val_mse: 4.9819e-04\n",
            "Epoch 159/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 5.1986e-04 - mse: 0.0010\n",
            "Epoch 159: val_loss improved from 0.00025 to 0.00025, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 4.9102e-04 - mse: 9.8203e-04 - val_loss: 2.4670e-04 - val_mse: 4.9340e-04\n",
            "Epoch 160/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 5.2224e-04 - mse: 0.0010    \n",
            "Epoch 160: val_loss did not improve from 0.00025\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.9628e-04 - mse: 9.9255e-04 - val_loss: 2.6198e-04 - val_mse: 5.2397e-04\n",
            "Epoch 161/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.9837e-04 - mse: 9.9674e-04\n",
            "Epoch 161: val_loss did not improve from 0.00025\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.7803e-04 - mse: 9.5606e-04 - val_loss: 2.7100e-04 - val_mse: 5.4200e-04\n",
            "Epoch 162/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.8721e-04 - mse: 9.7442e-04\n",
            "Epoch 162: val_loss improved from 0.00025 to 0.00024, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 4.7708e-04 - mse: 9.5416e-04 - val_loss: 2.4383e-04 - val_mse: 4.8766e-04\n",
            "Epoch 163/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.7107e-04 - mse: 9.4214e-04\n",
            "Epoch 163: val_loss did not improve from 0.00024\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 5.2797e-04 - mse: 0.0011 - val_loss: 2.4660e-04 - val_mse: 4.9320e-04\n",
            "Epoch 164/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.6445e-04 - mse: 9.2889e-04\n",
            "Epoch 164: val_loss did not improve from 0.00024\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 5.1671e-04 - mse: 0.0010 - val_loss: 2.4835e-04 - val_mse: 4.9671e-04\n",
            "Epoch 165/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 6.6245e-04 - mse: 0.0013\n",
            "Epoch 165: val_loss did not improve from 0.00024\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 5.2842e-04 - mse: 0.0011 - val_loss: 2.5104e-04 - val_mse: 5.0208e-04\n",
            "Epoch 166/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.7216e-04 - mse: 9.4433e-04\n",
            "Epoch 166: val_loss did not improve from 0.00024\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.6083e-04 - mse: 9.2166e-04 - val_loss: 2.5184e-04 - val_mse: 5.0369e-04\n",
            "Epoch 167/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 3.9756e-04 - mse: 7.9512e-04\n",
            "Epoch 167: val_loss did not improve from 0.00024\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 4.5766e-04 - mse: 9.1532e-04 - val_loss: 2.5104e-04 - val_mse: 5.0208e-04\n",
            "Epoch 168/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.6010e-04 - mse: 9.2020e-04\n",
            "Epoch 168: val_loss did not improve from 0.00024\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.6433e-04 - mse: 9.2866e-04 - val_loss: 2.7433e-04 - val_mse: 5.4867e-04\n",
            "Epoch 169/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.3377e-04 - mse: 8.6755e-04\n",
            "Epoch 169: val_loss did not improve from 0.00024\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.5866e-04 - mse: 9.1733e-04 - val_loss: 2.8607e-04 - val_mse: 5.7214e-04\n",
            "Epoch 170/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.3764e-04 - mse: 8.7528e-04\n",
            "Epoch 170: val_loss did not improve from 0.00024\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.5438e-04 - mse: 9.0877e-04 - val_loss: 2.9327e-04 - val_mse: 5.8654e-04\n",
            "Epoch 171/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 5.3483e-04 - mse: 0.0011\n",
            "Epoch 171: val_loss did not improve from 0.00024\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.8230e-04 - mse: 9.6459e-04 - val_loss: 2.7678e-04 - val_mse: 5.5356e-04\n",
            "Epoch 172/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.8436e-04 - mse: 9.6873e-04\n",
            "Epoch 172: val_loss did not improve from 0.00024\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.5748e-04 - mse: 9.1497e-04 - val_loss: 2.6708e-04 - val_mse: 5.3416e-04\n",
            "Epoch 173/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.9938e-04 - mse: 9.9875e-04\n",
            "Epoch 173: val_loss improved from 0.00024 to 0.00024, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 4.7172e-04 - mse: 9.4344e-04 - val_loss: 2.3943e-04 - val_mse: 4.7885e-04\n",
            "Epoch 174/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 4.3882e-04 - mse: 8.7764e-04\n",
            "Epoch 174: val_loss improved from 0.00024 to 0.00023, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 4.6295e-04 - mse: 9.2589e-04 - val_loss: 2.3313e-04 - val_mse: 4.6627e-04\n",
            "Epoch 175/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 4.7957e-04 - mse: 9.5914e-04\n",
            "Epoch 175: val_loss did not improve from 0.00023\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.6056e-04 - mse: 9.2113e-04 - val_loss: 2.5258e-04 - val_mse: 5.0516e-04\n",
            "Epoch 176/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 4.6785e-04 - mse: 9.3571e-04\n",
            "Epoch 176: val_loss did not improve from 0.00023\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 4.8829e-04 - mse: 9.7659e-04 - val_loss: 2.5916e-04 - val_mse: 5.1831e-04\n",
            "Epoch 177/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.7823e-04 - mse: 9.5646e-04\n",
            "Epoch 177: val_loss did not improve from 0.00023\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.1443e-04 - mse: 0.0010 - val_loss: 2.4672e-04 - val_mse: 4.9343e-04\n",
            "Epoch 178/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 5.9960e-04 - mse: 0.0012\n",
            "Epoch 178: val_loss did not improve from 0.00023\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.8028e-04 - mse: 0.0012 - val_loss: 2.7421e-04 - val_mse: 5.4841e-04\n",
            "Epoch 179/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.9088e-04 - mse: 9.8175e-04\n",
            "Epoch 179: val_loss did not improve from 0.00023\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.8475e-04 - mse: 9.6949e-04 - val_loss: 2.7537e-04 - val_mse: 5.5074e-04\n",
            "Epoch 180/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.8078e-04 - mse: 9.6156e-04\n",
            "Epoch 180: val_loss did not improve from 0.00023\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 4.5914e-04 - mse: 9.1828e-04 - val_loss: 2.8842e-04 - val_mse: 5.7684e-04\n",
            "Epoch 181/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.8450e-04 - mse: 9.6900e-04\n",
            "Epoch 181: val_loss did not improve from 0.00023\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.4763e-04 - mse: 8.9526e-04 - val_loss: 2.6161e-04 - val_mse: 5.2322e-04\n",
            "Epoch 182/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.9368e-04 - mse: 9.8735e-04\n",
            "Epoch 182: val_loss did not improve from 0.00023\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.6685e-04 - mse: 9.3370e-04 - val_loss: 2.3403e-04 - val_mse: 4.6806e-04\n",
            "Epoch 183/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.0568e-04 - mse: 8.1137e-04\n",
            "Epoch 183: val_loss did not improve from 0.00023\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.4203e-04 - mse: 8.8406e-04 - val_loss: 2.3469e-04 - val_mse: 4.6938e-04\n",
            "Epoch 184/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.7684e-04 - mse: 9.5367e-04\n",
            "Epoch 184: val_loss improved from 0.00023 to 0.00023, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 4.6914e-04 - mse: 9.3829e-04 - val_loss: 2.2889e-04 - val_mse: 4.5777e-04\n",
            "Epoch 185/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.3364e-04 - mse: 8.6729e-04\n",
            "Epoch 185: val_loss did not improve from 0.00023\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.4838e-04 - mse: 8.9677e-04 - val_loss: 2.3347e-04 - val_mse: 4.6693e-04\n",
            "Epoch 186/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.2772e-04 - mse: 8.5543e-04\n",
            "Epoch 186: val_loss did not improve from 0.00023\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 4.3130e-04 - mse: 8.6260e-04 - val_loss: 2.3153e-04 - val_mse: 4.6306e-04\n",
            "Epoch 187/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 5.4344e-04 - mse: 0.0011\n",
            "Epoch 187: val_loss did not improve from 0.00023\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.9867e-04 - mse: 9.9734e-04 - val_loss: 2.3455e-04 - val_mse: 4.6911e-04\n",
            "Epoch 188/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.7942e-04 - mse: 7.5885e-04\n",
            "Epoch 188: val_loss improved from 0.00023 to 0.00023, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 4.3632e-04 - mse: 8.7264e-04 - val_loss: 2.2576e-04 - val_mse: 4.5151e-04\n",
            "Epoch 189/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.5337e-04 - mse: 9.0673e-04\n",
            "Epoch 189: val_loss did not improve from 0.00023\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.4431e-04 - mse: 8.8862e-04 - val_loss: 2.2739e-04 - val_mse: 4.5477e-04\n",
            "Epoch 190/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.6059e-04 - mse: 9.2119e-04\n",
            "Epoch 190: val_loss did not improve from 0.00023\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.5086e-04 - mse: 9.0173e-04 - val_loss: 2.3153e-04 - val_mse: 4.6307e-04\n",
            "Epoch 191/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.8044e-04 - mse: 9.6088e-04\n",
            "Epoch 191: val_loss did not improve from 0.00023\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.4679e-04 - mse: 8.9358e-04 - val_loss: 2.4174e-04 - val_mse: 4.8348e-04\n",
            "Epoch 192/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.9243e-04 - mse: 9.8486e-04\n",
            "Epoch 192: val_loss did not improve from 0.00023\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 4.7176e-04 - mse: 9.4352e-04 - val_loss: 3.0800e-04 - val_mse: 6.1601e-04\n",
            "Epoch 193/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.6921e-04 - mse: 9.3841e-04\n",
            "Epoch 193: val_loss did not improve from 0.00023\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 4.7637e-04 - mse: 9.5274e-04 - val_loss: 3.2589e-04 - val_mse: 6.5179e-04\n",
            "Epoch 194/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 5.2597e-04 - mse: 0.0011\n",
            "Epoch 194: val_loss did not improve from 0.00023\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 4.8430e-04 - mse: 9.6861e-04 - val_loss: 2.6758e-04 - val_mse: 5.3516e-04\n",
            "Epoch 195/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 4.3711e-04 - mse: 8.7421e-04\n",
            "Epoch 195: val_loss did not improve from 0.00023\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 4.6846e-04 - mse: 9.3692e-04 - val_loss: 2.3736e-04 - val_mse: 4.7472e-04\n",
            "Epoch 196/2000\n",
            " 6/12 [==============>...............] - ETA: 0s - loss: 4.5012e-04 - mse: 9.0024e-04\n",
            "Epoch 196: val_loss did not improve from 0.00023\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 4.4188e-04 - mse: 8.8376e-04 - val_loss: 2.6346e-04 - val_mse: 5.2691e-04\n",
            "Epoch 197/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.9925e-04 - mse: 7.9850e-04\n",
            "Epoch 197: val_loss did not improve from 0.00023\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 4.3235e-04 - mse: 8.6469e-04 - val_loss: 2.2845e-04 - val_mse: 4.5689e-04\n",
            "Epoch 198/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.1388e-04 - mse: 8.2775e-04\n",
            "Epoch 198: val_loss improved from 0.00023 to 0.00022, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 4.2169e-04 - mse: 8.4337e-04 - val_loss: 2.1970e-04 - val_mse: 4.3940e-04\n",
            "Epoch 199/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 4.7211e-04 - mse: 9.4422e-04\n",
            "Epoch 199: val_loss did not improve from 0.00022\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 4.3614e-04 - mse: 8.7229e-04 - val_loss: 2.3168e-04 - val_mse: 4.6335e-04\n",
            "Epoch 200/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 4.3390e-04 - mse: 8.6781e-04\n",
            "Epoch 200: val_loss improved from 0.00022 to 0.00021, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 4.4048e-04 - mse: 8.8096e-04 - val_loss: 2.1452e-04 - val_mse: 4.2904e-04\n",
            "Epoch 201/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.0728e-04 - mse: 8.1456e-04\n",
            "Epoch 201: val_loss did not improve from 0.00021\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 4.2118e-04 - mse: 8.4237e-04 - val_loss: 2.1881e-04 - val_mse: 4.3762e-04\n",
            "Epoch 202/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.3164e-04 - mse: 8.6328e-04\n",
            "Epoch 202: val_loss did not improve from 0.00021\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 4.2777e-04 - mse: 8.5554e-04 - val_loss: 2.4444e-04 - val_mse: 4.8887e-04\n",
            "Epoch 203/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.5044e-04 - mse: 9.0089e-04\n",
            "Epoch 203: val_loss did not improve from 0.00021\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 4.4438e-04 - mse: 8.8875e-04 - val_loss: 2.1961e-04 - val_mse: 4.3922e-04\n",
            "Epoch 204/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.4955e-04 - mse: 8.9911e-04\n",
            "Epoch 204: val_loss did not improve from 0.00021\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 4.2845e-04 - mse: 8.5690e-04 - val_loss: 2.2997e-04 - val_mse: 4.5993e-04\n",
            "Epoch 205/2000\n",
            " 6/12 [==============>...............] - ETA: 0s - loss: 4.7967e-04 - mse: 9.5933e-04\n",
            "Epoch 205: val_loss did not improve from 0.00021\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 4.3373e-04 - mse: 8.6745e-04 - val_loss: 2.7383e-04 - val_mse: 5.4767e-04\n",
            "Epoch 206/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 5.4389e-04 - mse: 0.0011\n",
            "Epoch 206: val_loss did not improve from 0.00021\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 4.5097e-04 - mse: 9.0193e-04 - val_loss: 2.2312e-04 - val_mse: 4.4625e-04\n",
            "Epoch 207/2000\n",
            " 6/12 [==============>...............] - ETA: 0s - loss: 3.7381e-04 - mse: 7.4763e-04\n",
            "Epoch 207: val_loss did not improve from 0.00021\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 4.2934e-04 - mse: 8.5869e-04 - val_loss: 2.1730e-04 - val_mse: 4.3460e-04\n",
            "Epoch 208/2000\n",
            "12/12 [==============================] - ETA: 0s - loss: 4.2305e-04 - mse: 8.4609e-04\n",
            "Epoch 208: val_loss did not improve from 0.00021\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 4.2305e-04 - mse: 8.4609e-04 - val_loss: 2.1613e-04 - val_mse: 4.3226e-04\n",
            "Epoch 209/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 5.0258e-04 - mse: 0.0010    \n",
            "Epoch 209: val_loss did not improve from 0.00021\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 4.3871e-04 - mse: 8.7742e-04 - val_loss: 2.2388e-04 - val_mse: 4.4775e-04\n",
            "Epoch 210/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.6122e-04 - mse: 9.2243e-04\n",
            "Epoch 210: val_loss improved from 0.00021 to 0.00021, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 4.8331e-04 - mse: 9.6662e-04 - val_loss: 2.0891e-04 - val_mse: 4.1783e-04\n",
            "Epoch 211/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.5283e-04 - mse: 9.0567e-04\n",
            "Epoch 211: val_loss did not improve from 0.00021\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.3967e-04 - mse: 8.7934e-04 - val_loss: 2.3176e-04 - val_mse: 4.6352e-04\n",
            "Epoch 212/2000\n",
            "12/12 [==============================] - ETA: 0s - loss: 4.2877e-04 - mse: 8.5753e-04\n",
            "Epoch 212: val_loss did not improve from 0.00021\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.2877e-04 - mse: 8.5753e-04 - val_loss: 2.4507e-04 - val_mse: 4.9014e-04\n",
            "Epoch 213/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 4.5495e-04 - mse: 9.0990e-04\n",
            "Epoch 213: val_loss did not improve from 0.00021\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.3899e-04 - mse: 8.7798e-04 - val_loss: 2.2941e-04 - val_mse: 4.5883e-04\n",
            "Epoch 214/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.3735e-04 - mse: 8.7471e-04\n",
            "Epoch 214: val_loss did not improve from 0.00021\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.1494e-04 - mse: 8.2989e-04 - val_loss: 2.7574e-04 - val_mse: 5.5148e-04\n",
            "Epoch 215/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.2577e-04 - mse: 8.5154e-04\n",
            "Epoch 215: val_loss did not improve from 0.00021\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.2675e-04 - mse: 8.5350e-04 - val_loss: 2.7367e-04 - val_mse: 5.4734e-04\n",
            "Epoch 216/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 5.0874e-04 - mse: 0.0010\n",
            "Epoch 216: val_loss did not improve from 0.00021\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.5752e-04 - mse: 9.1505e-04 - val_loss: 2.9147e-04 - val_mse: 5.8293e-04\n",
            "Epoch 217/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.3651e-04 - mse: 8.7303e-04\n",
            "Epoch 217: val_loss did not improve from 0.00021\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.2523e-04 - mse: 8.5046e-04 - val_loss: 2.2230e-04 - val_mse: 4.4460e-04\n",
            "Epoch 218/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.5972e-04 - mse: 9.1943e-04\n",
            "Epoch 218: val_loss did not improve from 0.00021\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.1547e-04 - mse: 8.3094e-04 - val_loss: 2.2424e-04 - val_mse: 4.4848e-04\n",
            "Epoch 219/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.2122e-04 - mse: 8.4243e-04\n",
            "Epoch 219: val_loss improved from 0.00021 to 0.00021, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 4.0919e-04 - mse: 8.1837e-04 - val_loss: 2.0678e-04 - val_mse: 4.1356e-04\n",
            "Epoch 220/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.9913e-04 - mse: 7.9826e-04\n",
            "Epoch 220: val_loss did not improve from 0.00021\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.0805e-04 - mse: 8.1611e-04 - val_loss: 2.3310e-04 - val_mse: 4.6621e-04\n",
            "Epoch 221/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.9700e-04 - mse: 7.9400e-04\n",
            "Epoch 221: val_loss improved from 0.00021 to 0.00020, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 4.3354e-04 - mse: 8.6707e-04 - val_loss: 2.0482e-04 - val_mse: 4.0964e-04\n",
            "Epoch 222/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.5902e-04 - mse: 9.1804e-04\n",
            "Epoch 222: val_loss did not improve from 0.00020\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.2405e-04 - mse: 8.4810e-04 - val_loss: 2.0565e-04 - val_mse: 4.1130e-04\n",
            "Epoch 223/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 4.4417e-04 - mse: 8.8834e-04\n",
            "Epoch 223: val_loss did not improve from 0.00020\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 4.1055e-04 - mse: 8.2111e-04 - val_loss: 2.4164e-04 - val_mse: 4.8327e-04\n",
            "Epoch 224/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.7191e-04 - mse: 9.4381e-04\n",
            "Epoch 224: val_loss improved from 0.00020 to 0.00020, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 4.6578e-04 - mse: 9.3156e-04 - val_loss: 2.0100e-04 - val_mse: 4.0201e-04\n",
            "Epoch 225/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 5.0284e-04 - mse: 0.0010\n",
            "Epoch 225: val_loss did not improve from 0.00020\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.8826e-04 - mse: 9.7651e-04 - val_loss: 2.0587e-04 - val_mse: 4.1174e-04\n",
            "Epoch 226/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.2136e-04 - mse: 8.4272e-04\n",
            "Epoch 226: val_loss did not improve from 0.00020\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.3670e-04 - mse: 8.7340e-04 - val_loss: 2.1248e-04 - val_mse: 4.2496e-04\n",
            "Epoch 227/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.4165e-04 - mse: 8.8331e-04\n",
            "Epoch 227: val_loss did not improve from 0.00020\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.2114e-04 - mse: 8.4228e-04 - val_loss: 2.0316e-04 - val_mse: 4.0632e-04\n",
            "Epoch 228/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.0744e-04 - mse: 8.1489e-04\n",
            "Epoch 228: val_loss did not improve from 0.00020\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.0572e-04 - mse: 8.1144e-04 - val_loss: 2.3119e-04 - val_mse: 4.6238e-04\n",
            "Epoch 229/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.2675e-04 - mse: 8.5350e-04\n",
            "Epoch 229: val_loss did not improve from 0.00020\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.9677e-04 - mse: 7.9354e-04 - val_loss: 2.1854e-04 - val_mse: 4.3708e-04\n",
            "Epoch 230/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.0180e-04 - mse: 8.0361e-04\n",
            "Epoch 230: val_loss did not improve from 0.00020\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.0656e-04 - mse: 8.1312e-04 - val_loss: 2.2354e-04 - val_mse: 4.4708e-04\n",
            "Epoch 231/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.8857e-04 - mse: 7.7713e-04\n",
            "Epoch 231: val_loss did not improve from 0.00020\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.2883e-04 - mse: 8.5765e-04 - val_loss: 2.3173e-04 - val_mse: 4.6345e-04\n",
            "Epoch 232/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 4.2627e-04 - mse: 8.5254e-04\n",
            "Epoch 232: val_loss did not improve from 0.00020\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.0033e-04 - mse: 8.0066e-04 - val_loss: 2.2080e-04 - val_mse: 4.4160e-04\n",
            "Epoch 233/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.4974e-04 - mse: 6.9947e-04\n",
            "Epoch 233: val_loss did not improve from 0.00020\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.0108e-04 - mse: 8.0216e-04 - val_loss: 2.4095e-04 - val_mse: 4.8190e-04\n",
            "Epoch 234/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.0733e-04 - mse: 8.1466e-04\n",
            "Epoch 234: val_loss did not improve from 0.00020\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.0336e-04 - mse: 8.0671e-04 - val_loss: 2.2462e-04 - val_mse: 4.4925e-04\n",
            "Epoch 235/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.4083e-04 - mse: 8.8166e-04\n",
            "Epoch 235: val_loss did not improve from 0.00020\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.4160e-04 - mse: 8.8319e-04 - val_loss: 3.4523e-04 - val_mse: 6.9047e-04\n",
            "Epoch 236/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 5.1850e-04 - mse: 0.0010    \n",
            "Epoch 236: val_loss did not improve from 0.00020\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 5.0443e-04 - mse: 0.0010 - val_loss: 3.2451e-04 - val_mse: 6.4902e-04\n",
            "Epoch 237/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 5.8902e-04 - mse: 0.0012\n",
            "Epoch 237: val_loss did not improve from 0.00020\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.5781e-04 - mse: 0.0011 - val_loss: 2.4863e-04 - val_mse: 4.9726e-04\n",
            "Epoch 238/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 4.8935e-04 - mse: 9.7870e-04\n",
            "Epoch 238: val_loss improved from 0.00020 to 0.00020, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 4.6953e-04 - mse: 9.3907e-04 - val_loss: 1.9944e-04 - val_mse: 3.9887e-04\n",
            "Epoch 239/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.0844e-04 - mse: 8.1689e-04\n",
            "Epoch 239: val_loss improved from 0.00020 to 0.00020, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 4.2095e-04 - mse: 8.4191e-04 - val_loss: 1.9688e-04 - val_mse: 3.9376e-04\n",
            "Epoch 240/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.6317e-04 - mse: 7.2634e-04\n",
            "Epoch 240: val_loss improved from 0.00020 to 0.00020, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 4.1264e-04 - mse: 8.2528e-04 - val_loss: 1.9648e-04 - val_mse: 3.9296e-04\n",
            "Epoch 241/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.1611e-04 - mse: 8.3222e-04\n",
            "Epoch 241: val_loss did not improve from 0.00020\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.4059e-04 - mse: 8.8118e-04 - val_loss: 2.3865e-04 - val_mse: 4.7729e-04\n",
            "Epoch 242/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.6442e-04 - mse: 9.2884e-04\n",
            "Epoch 242: val_loss did not improve from 0.00020\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.5263e-04 - mse: 9.0525e-04 - val_loss: 2.0659e-04 - val_mse: 4.1319e-04\n",
            "Epoch 243/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.1116e-04 - mse: 8.2231e-04\n",
            "Epoch 243: val_loss did not improve from 0.00020\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.1149e-04 - mse: 8.2299e-04 - val_loss: 2.1599e-04 - val_mse: 4.3199e-04\n",
            "Epoch 244/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 4.1633e-04 - mse: 8.3266e-04\n",
            "Epoch 244: val_loss did not improve from 0.00020\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.9310e-04 - mse: 7.8620e-04 - val_loss: 2.0791e-04 - val_mse: 4.1583e-04\n",
            "Epoch 245/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 4.2360e-04 - mse: 8.4720e-04\n",
            "Epoch 245: val_loss did not improve from 0.00020\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 4.0564e-04 - mse: 8.1128e-04 - val_loss: 2.0165e-04 - val_mse: 4.0330e-04\n",
            "Epoch 246/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.7298e-04 - mse: 9.4597e-04\n",
            "Epoch 246: val_loss did not improve from 0.00020\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.3509e-04 - mse: 8.7018e-04 - val_loss: 1.9955e-04 - val_mse: 3.9910e-04\n",
            "Epoch 247/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 3.8659e-04 - mse: 7.7318e-04\n",
            "Epoch 247: val_loss did not improve from 0.00020\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.0621e-04 - mse: 8.1241e-04 - val_loss: 2.0897e-04 - val_mse: 4.1794e-04\n",
            "Epoch 248/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.0151e-04 - mse: 8.0301e-04\n",
            "Epoch 248: val_loss did not improve from 0.00020\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3.8542e-04 - mse: 7.7084e-04 - val_loss: 2.1573e-04 - val_mse: 4.3147e-04\n",
            "Epoch 249/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 4.0876e-04 - mse: 8.1752e-04\n",
            "Epoch 249: val_loss did not improve from 0.00020\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.0093e-04 - mse: 8.0186e-04 - val_loss: 2.1860e-04 - val_mse: 4.3720e-04\n",
            "Epoch 250/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.5557e-04 - mse: 7.1115e-04\n",
            "Epoch 250: val_loss did not improve from 0.00020\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.8479e-04 - mse: 7.6959e-04 - val_loss: 2.0611e-04 - val_mse: 4.1222e-04\n",
            "Epoch 251/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 4.2851e-04 - mse: 8.5703e-04\n",
            "Epoch 251: val_loss did not improve from 0.00020\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.9843e-04 - mse: 7.9685e-04 - val_loss: 2.4961e-04 - val_mse: 4.9922e-04\n",
            "Epoch 252/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.0848e-04 - mse: 8.1696e-04\n",
            "Epoch 252: val_loss did not improve from 0.00020\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 3.9532e-04 - mse: 7.9064e-04 - val_loss: 2.3374e-04 - val_mse: 4.6747e-04\n",
            "Epoch 253/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.7673e-04 - mse: 7.5345e-04\n",
            "Epoch 253: val_loss improved from 0.00020 to 0.00020, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 3.7390e-04 - mse: 7.4780e-04 - val_loss: 1.9592e-04 - val_mse: 3.9184e-04\n",
            "Epoch 254/2000\n",
            " 6/12 [==============>...............] - ETA: 0s - loss: 4.2368e-04 - mse: 8.4737e-04\n",
            "Epoch 254: val_loss improved from 0.00020 to 0.00019, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 4.3662e-04 - mse: 8.7324e-04 - val_loss: 1.9359e-04 - val_mse: 3.8717e-04\n",
            "Epoch 255/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 4.0430e-04 - mse: 8.0861e-04\n",
            "Epoch 255: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 4.0724e-04 - mse: 8.1447e-04 - val_loss: 1.9484e-04 - val_mse: 3.8968e-04\n",
            "Epoch 256/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 4.6750e-04 - mse: 9.3499e-04\n",
            "Epoch 256: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 4.6570e-04 - mse: 9.3139e-04 - val_loss: 2.3861e-04 - val_mse: 4.7723e-04\n",
            "Epoch 257/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 5.3506e-04 - mse: 0.0011\n",
            "Epoch 257: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 5.1294e-04 - mse: 0.0010 - val_loss: 1.9720e-04 - val_mse: 3.9440e-04\n",
            "Epoch 258/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 4.4347e-04 - mse: 8.8695e-04\n",
            "Epoch 258: val_loss improved from 0.00019 to 0.00019, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 4.2943e-04 - mse: 8.5886e-04 - val_loss: 1.8981e-04 - val_mse: 3.7962e-04\n",
            "Epoch 259/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.2716e-04 - mse: 8.5432e-04\n",
            "Epoch 259: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.8986e-04 - mse: 7.7972e-04 - val_loss: 2.3225e-04 - val_mse: 4.6450e-04\n",
            "Epoch 260/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.8081e-04 - mse: 7.6162e-04\n",
            "Epoch 260: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.2435e-04 - mse: 8.4869e-04 - val_loss: 2.5283e-04 - val_mse: 5.0566e-04\n",
            "Epoch 261/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 4.3932e-04 - mse: 8.7864e-04\n",
            "Epoch 261: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.9558e-04 - mse: 7.9115e-04 - val_loss: 2.4937e-04 - val_mse: 4.9874e-04\n",
            "Epoch 262/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 4.6864e-04 - mse: 9.3728e-04\n",
            "Epoch 262: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.2557e-04 - mse: 8.5114e-04 - val_loss: 2.7182e-04 - val_mse: 5.4365e-04\n",
            "Epoch 263/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.9421e-04 - mse: 9.8841e-04\n",
            "Epoch 263: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.9623e-04 - mse: 9.9246e-04 - val_loss: 3.8988e-04 - val_mse: 7.7975e-04\n",
            "Epoch 264/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.5215e-04 - mse: 9.0431e-04\n",
            "Epoch 264: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.7552e-04 - mse: 9.5104e-04 - val_loss: 2.5164e-04 - val_mse: 5.0327e-04\n",
            "Epoch 265/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.5213e-04 - mse: 9.0426e-04\n",
            "Epoch 265: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.2129e-04 - mse: 8.4258e-04 - val_loss: 2.2600e-04 - val_mse: 4.5201e-04\n",
            "Epoch 266/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.9842e-04 - mse: 7.9684e-04\n",
            "Epoch 266: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.0418e-04 - mse: 8.0837e-04 - val_loss: 2.1840e-04 - val_mse: 4.3681e-04\n",
            "Epoch 267/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.3674e-04 - mse: 8.7348e-04\n",
            "Epoch 267: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.2059e-04 - mse: 8.4119e-04 - val_loss: 2.3981e-04 - val_mse: 4.7963e-04\n",
            "Epoch 268/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.8355e-04 - mse: 7.6710e-04\n",
            "Epoch 268: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.7707e-04 - mse: 7.5415e-04 - val_loss: 2.6627e-04 - val_mse: 5.3255e-04\n",
            "Epoch 269/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.9293e-04 - mse: 7.8587e-04\n",
            "Epoch 269: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.8834e-04 - mse: 7.7667e-04 - val_loss: 1.9649e-04 - val_mse: 3.9298e-04\n",
            "Epoch 270/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.5364e-04 - mse: 7.0728e-04\n",
            "Epoch 270: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.7986e-04 - mse: 7.5973e-04 - val_loss: 2.0110e-04 - val_mse: 4.0220e-04\n",
            "Epoch 271/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 4.3070e-04 - mse: 8.6140e-04\n",
            "Epoch 271: val_loss improved from 0.00019 to 0.00019, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 4.0297e-04 - mse: 8.0595e-04 - val_loss: 1.8758e-04 - val_mse: 3.7516e-04\n",
            "Epoch 272/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.8514e-04 - mse: 7.7029e-04\n",
            "Epoch 272: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.0814e-04 - mse: 8.1627e-04 - val_loss: 2.0758e-04 - val_mse: 4.1515e-04\n",
            "Epoch 273/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.6482e-04 - mse: 9.2963e-04\n",
            "Epoch 273: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.6172e-04 - mse: 9.2344e-04 - val_loss: 2.3822e-04 - val_mse: 4.7644e-04\n",
            "Epoch 274/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 4.2936e-04 - mse: 8.5871e-04\n",
            "Epoch 274: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.1489e-04 - mse: 8.2977e-04 - val_loss: 1.9545e-04 - val_mse: 3.9089e-04\n",
            "Epoch 275/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.0121e-04 - mse: 8.0242e-04\n",
            "Epoch 275: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3.9031e-04 - mse: 7.8062e-04 - val_loss: 2.4390e-04 - val_mse: 4.8780e-04\n",
            "Epoch 276/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.9953e-04 - mse: 7.9905e-04\n",
            "Epoch 276: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.2792e-04 - mse: 8.5583e-04 - val_loss: 2.3933e-04 - val_mse: 4.7865e-04\n",
            "Epoch 277/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.9238e-04 - mse: 7.8476e-04\n",
            "Epoch 277: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.2919e-04 - mse: 8.5837e-04 - val_loss: 2.6856e-04 - val_mse: 5.3712e-04\n",
            "Epoch 278/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.1934e-04 - mse: 8.3869e-04\n",
            "Epoch 278: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.0927e-04 - mse: 8.1854e-04 - val_loss: 2.9185e-04 - val_mse: 5.8371e-04\n",
            "Epoch 279/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 4.6437e-04 - mse: 9.2874e-04\n",
            "Epoch 279: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.0844e-04 - mse: 8.1688e-04 - val_loss: 2.0651e-04 - val_mse: 4.1303e-04\n",
            "Epoch 280/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.9070e-04 - mse: 7.8141e-04\n",
            "Epoch 280: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.7088e-04 - mse: 7.4177e-04 - val_loss: 1.9103e-04 - val_mse: 3.8206e-04\n",
            "Epoch 281/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.9281e-04 - mse: 9.8562e-04\n",
            "Epoch 281: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.7340e-04 - mse: 9.4681e-04 - val_loss: 1.9616e-04 - val_mse: 3.9233e-04\n",
            "Epoch 282/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.9167e-04 - mse: 7.8334e-04\n",
            "Epoch 282: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.9423e-04 - mse: 7.8847e-04 - val_loss: 2.0306e-04 - val_mse: 4.0611e-04\n",
            "Epoch 283/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.9371e-04 - mse: 7.8741e-04\n",
            "Epoch 283: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3.8666e-04 - mse: 7.7331e-04 - val_loss: 1.9483e-04 - val_mse: 3.8966e-04\n",
            "Epoch 284/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 4.0150e-04 - mse: 8.0301e-04\n",
            "Epoch 284: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.7611e-04 - mse: 7.5222e-04 - val_loss: 2.0743e-04 - val_mse: 4.1486e-04\n",
            "Epoch 285/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.6193e-04 - mse: 7.2387e-04\n",
            "Epoch 285: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.8709e-04 - mse: 7.7418e-04 - val_loss: 2.3731e-04 - val_mse: 4.7463e-04\n",
            "Epoch 286/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.6868e-04 - mse: 9.3736e-04\n",
            "Epoch 286: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.4537e-04 - mse: 8.9075e-04 - val_loss: 2.0834e-04 - val_mse: 4.1668e-04\n",
            "Epoch 287/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.1258e-04 - mse: 8.2515e-04\n",
            "Epoch 287: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.0656e-04 - mse: 8.1312e-04 - val_loss: 2.5938e-04 - val_mse: 5.1877e-04\n",
            "Epoch 288/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.3024e-04 - mse: 8.6048e-04\n",
            "Epoch 288: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.0019e-04 - mse: 8.0037e-04 - val_loss: 2.1541e-04 - val_mse: 4.3081e-04\n",
            "Epoch 289/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.9036e-04 - mse: 7.8073e-04\n",
            "Epoch 289: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.9168e-04 - mse: 7.8336e-04 - val_loss: 1.9751e-04 - val_mse: 3.9502e-04\n",
            "Epoch 290/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.8785e-04 - mse: 7.7570e-04\n",
            "Epoch 290: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.7741e-04 - mse: 7.5482e-04 - val_loss: 2.1315e-04 - val_mse: 4.2630e-04\n",
            "Epoch 291/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.4369e-04 - mse: 6.8738e-04\n",
            "Epoch 291: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.9939e-04 - mse: 7.9877e-04 - val_loss: 2.4158e-04 - val_mse: 4.8316e-04\n",
            "Epoch 292/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.2895e-04 - mse: 8.5790e-04\n",
            "Epoch 292: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.0278e-04 - mse: 8.0555e-04 - val_loss: 2.2923e-04 - val_mse: 4.5845e-04\n",
            "Epoch 293/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 3.7012e-04 - mse: 7.4025e-04\n",
            "Epoch 293: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.8414e-04 - mse: 7.6828e-04 - val_loss: 2.0741e-04 - val_mse: 4.1482e-04\n",
            "Epoch 294/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.6569e-04 - mse: 7.3138e-04\n",
            "Epoch 294: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.7303e-04 - mse: 7.4605e-04 - val_loss: 1.9929e-04 - val_mse: 3.9858e-04\n",
            "Epoch 295/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 3.9240e-04 - mse: 7.8480e-04\n",
            "Epoch 295: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3.8232e-04 - mse: 7.6465e-04 - val_loss: 2.0849e-04 - val_mse: 4.1698e-04\n",
            "Epoch 296/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.5046e-04 - mse: 7.0091e-04\n",
            "Epoch 296: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.7723e-04 - mse: 7.5446e-04 - val_loss: 2.2650e-04 - val_mse: 4.5300e-04\n",
            "Epoch 297/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.0247e-04 - mse: 8.0493e-04\n",
            "Epoch 297: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3.9422e-04 - mse: 7.8844e-04 - val_loss: 1.8926e-04 - val_mse: 3.7853e-04\n",
            "Epoch 298/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.6156e-04 - mse: 7.2311e-04\n",
            "Epoch 298: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3.8617e-04 - mse: 7.7233e-04 - val_loss: 1.9489e-04 - val_mse: 3.8978e-04\n",
            "Epoch 299/2000\n",
            "12/12 [==============================] - ETA: 0s - loss: 4.0333e-04 - mse: 8.0667e-04\n",
            "Epoch 299: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 4.0333e-04 - mse: 8.0667e-04 - val_loss: 3.1406e-04 - val_mse: 6.2813e-04\n",
            "Epoch 300/2000\n",
            " 6/12 [==============>...............] - ETA: 0s - loss: 3.4866e-04 - mse: 6.9732e-04\n",
            "Epoch 300: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 4.2225e-04 - mse: 8.4451e-04 - val_loss: 2.1424e-04 - val_mse: 4.2848e-04\n",
            "Epoch 301/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 4.1733e-04 - mse: 8.3465e-04\n",
            "Epoch 301: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 3.9277e-04 - mse: 7.8555e-04 - val_loss: 2.6091e-04 - val_mse: 5.2182e-04\n",
            "Epoch 302/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.9043e-04 - mse: 7.8086e-04\n",
            "Epoch 302: val_loss did not improve from 0.00019\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 4.0312e-04 - mse: 8.0624e-04 - val_loss: 2.4397e-04 - val_mse: 4.8794e-04\n",
            "Epoch 303/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 4.0994e-04 - mse: 8.1988e-04\n",
            "Epoch 303: val_loss improved from 0.00019 to 0.00018, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 4.0457e-04 - mse: 8.0914e-04 - val_loss: 1.8139e-04 - val_mse: 3.6278e-04\n",
            "Epoch 304/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 3.2262e-04 - mse: 6.4524e-04\n",
            "Epoch 304: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 4.0070e-04 - mse: 8.0139e-04 - val_loss: 2.0255e-04 - val_mse: 4.0509e-04\n",
            "Epoch 305/2000\n",
            "12/12 [==============================] - ETA: 0s - loss: 4.6158e-04 - mse: 9.2316e-04\n",
            "Epoch 305: val_loss improved from 0.00018 to 0.00018, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 4.6158e-04 - mse: 9.2316e-04 - val_loss: 1.8135e-04 - val_mse: 3.6270e-04\n",
            "Epoch 306/2000\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.6529e-04 - mse: 7.3058e-04\n",
            "Epoch 306: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 3.6529e-04 - mse: 7.3058e-04 - val_loss: 2.2909e-04 - val_mse: 4.5819e-04\n",
            "Epoch 307/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.8162e-04 - mse: 7.6324e-04\n",
            "Epoch 307: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 3.7260e-04 - mse: 7.4520e-04 - val_loss: 1.8503e-04 - val_mse: 3.7006e-04\n",
            "Epoch 308/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 3.6254e-04 - mse: 7.2507e-04\n",
            "Epoch 308: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 3.5980e-04 - mse: 7.1961e-04 - val_loss: 1.8460e-04 - val_mse: 3.6919e-04\n",
            "Epoch 309/2000\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.6706e-04 - mse: 7.3412e-04\n",
            "Epoch 309: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 3.6706e-04 - mse: 7.3412e-04 - val_loss: 2.3816e-04 - val_mse: 4.7632e-04\n",
            "Epoch 310/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 3.4708e-04 - mse: 6.9415e-04\n",
            "Epoch 310: val_loss improved from 0.00018 to 0.00018, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 3.7514e-04 - mse: 7.5027e-04 - val_loss: 1.8004e-04 - val_mse: 3.6008e-04\n",
            "Epoch 311/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.0438e-04 - mse: 8.0876e-04\n",
            "Epoch 311: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.9094e-04 - mse: 7.8188e-04 - val_loss: 1.8071e-04 - val_mse: 3.6142e-04\n",
            "Epoch 312/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.2819e-04 - mse: 8.5638e-04\n",
            "Epoch 312: val_loss improved from 0.00018 to 0.00018, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 4.0624e-04 - mse: 8.1247e-04 - val_loss: 1.7850e-04 - val_mse: 3.5700e-04\n",
            "Epoch 313/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.8728e-04 - mse: 7.7456e-04\n",
            "Epoch 313: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.1736e-04 - mse: 8.3472e-04 - val_loss: 1.8461e-04 - val_mse: 3.6922e-04\n",
            "Epoch 314/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.4572e-04 - mse: 6.9144e-04\n",
            "Epoch 314: val_loss improved from 0.00018 to 0.00018, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 3.6381e-04 - mse: 7.2762e-04 - val_loss: 1.7655e-04 - val_mse: 3.5309e-04\n",
            "Epoch 315/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.7864e-04 - mse: 7.5727e-04\n",
            "Epoch 315: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.6717e-04 - mse: 7.3434e-04 - val_loss: 1.7864e-04 - val_mse: 3.5727e-04\n",
            "Epoch 316/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.8530e-04 - mse: 7.7060e-04\n",
            "Epoch 316: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.7681e-04 - mse: 7.5361e-04 - val_loss: 2.2110e-04 - val_mse: 4.4220e-04\n",
            "Epoch 317/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.4084e-04 - mse: 6.8168e-04\n",
            "Epoch 317: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.7120e-04 - mse: 7.4240e-04 - val_loss: 2.0572e-04 - val_mse: 4.1144e-04\n",
            "Epoch 318/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.8502e-04 - mse: 7.7005e-04\n",
            "Epoch 318: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.0019e-04 - mse: 8.0037e-04 - val_loss: 1.9099e-04 - val_mse: 3.8197e-04\n",
            "Epoch 319/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.4197e-04 - mse: 8.8395e-04\n",
            "Epoch 319: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.3150e-04 - mse: 8.6299e-04 - val_loss: 2.1709e-04 - val_mse: 4.3417e-04\n",
            "Epoch 320/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.7784e-04 - mse: 7.5568e-04\n",
            "Epoch 320: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.6757e-04 - mse: 7.3514e-04 - val_loss: 2.2654e-04 - val_mse: 4.5308e-04\n",
            "Epoch 321/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 3.9624e-04 - mse: 7.9248e-04\n",
            "Epoch 321: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.9558e-04 - mse: 7.9115e-04 - val_loss: 1.7899e-04 - val_mse: 3.5797e-04\n",
            "Epoch 322/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.5670e-04 - mse: 7.1341e-04\n",
            "Epoch 322: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.6077e-04 - mse: 7.2154e-04 - val_loss: 1.8097e-04 - val_mse: 3.6193e-04\n",
            "Epoch 323/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.7372e-04 - mse: 7.4744e-04\n",
            "Epoch 323: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.6268e-04 - mse: 7.2536e-04 - val_loss: 1.9432e-04 - val_mse: 3.8863e-04\n",
            "Epoch 324/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.8712e-04 - mse: 7.7425e-04\n",
            "Epoch 324: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.6116e-04 - mse: 7.2232e-04 - val_loss: 1.7750e-04 - val_mse: 3.5500e-04\n",
            "Epoch 325/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.7357e-04 - mse: 7.4713e-04\n",
            "Epoch 325: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.5645e-04 - mse: 7.1290e-04 - val_loss: 2.2505e-04 - val_mse: 4.5010e-04\n",
            "Epoch 326/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.7557e-04 - mse: 7.5115e-04\n",
            "Epoch 326: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.6209e-04 - mse: 7.2418e-04 - val_loss: 1.8328e-04 - val_mse: 3.6656e-04\n",
            "Epoch 327/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.7298e-04 - mse: 7.4596e-04\n",
            "Epoch 327: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.5595e-04 - mse: 7.1191e-04 - val_loss: 2.2784e-04 - val_mse: 4.5569e-04\n",
            "Epoch 328/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.0118e-04 - mse: 8.0235e-04\n",
            "Epoch 328: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.7556e-04 - mse: 7.5112e-04 - val_loss: 3.3423e-04 - val_mse: 6.6846e-04\n",
            "Epoch 329/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 4.9994e-04 - mse: 9.9989e-04\n",
            "Epoch 329: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.5091e-04 - mse: 9.0182e-04 - val_loss: 2.6231e-04 - val_mse: 5.2461e-04\n",
            "Epoch 330/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.9097e-04 - mse: 7.8194e-04\n",
            "Epoch 330: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.8726e-04 - mse: 7.7451e-04 - val_loss: 2.8645e-04 - val_mse: 5.7290e-04\n",
            "Epoch 331/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.4575e-04 - mse: 8.9149e-04\n",
            "Epoch 331: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.1044e-04 - mse: 8.2088e-04 - val_loss: 2.0814e-04 - val_mse: 4.1627e-04\n",
            "Epoch 332/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.9467e-04 - mse: 7.8935e-04\n",
            "Epoch 332: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 3.6812e-04 - mse: 7.3623e-04 - val_loss: 3.4098e-04 - val_mse: 6.8196e-04\n",
            "Epoch 333/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.5647e-04 - mse: 9.1294e-04\n",
            "Epoch 333: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.4989e-04 - mse: 8.9977e-04 - val_loss: 2.6360e-04 - val_mse: 5.2720e-04\n",
            "Epoch 334/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.9203e-04 - mse: 7.8405e-04\n",
            "Epoch 334: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.0874e-04 - mse: 8.1747e-04 - val_loss: 1.9463e-04 - val_mse: 3.8927e-04\n",
            "Epoch 335/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.1091e-04 - mse: 8.2182e-04\n",
            "Epoch 335: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.0727e-04 - mse: 8.1454e-04 - val_loss: 1.8341e-04 - val_mse: 3.6681e-04\n",
            "Epoch 336/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 3.3260e-04 - mse: 6.6521e-04\n",
            "Epoch 336: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.5541e-04 - mse: 7.1083e-04 - val_loss: 2.1360e-04 - val_mse: 4.2720e-04\n",
            "Epoch 337/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.7183e-04 - mse: 7.4366e-04\n",
            "Epoch 337: val_loss did not improve from 0.00018\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3.8130e-04 - mse: 7.6260e-04 - val_loss: 2.5139e-04 - val_mse: 5.0279e-04\n",
            "Epoch 338/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.4326e-04 - mse: 6.8652e-04\n",
            "Epoch 338: val_loss improved from 0.00018 to 0.00017, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 3.7507e-04 - mse: 7.5013e-04 - val_loss: 1.7292e-04 - val_mse: 3.4583e-04\n",
            "Epoch 339/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.9438e-04 - mse: 7.8876e-04\n",
            "Epoch 339: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.6899e-04 - mse: 7.3798e-04 - val_loss: 1.7504e-04 - val_mse: 3.5009e-04\n",
            "Epoch 340/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 3.9735e-04 - mse: 7.9470e-04\n",
            "Epoch 340: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.7389e-04 - mse: 7.4778e-04 - val_loss: 1.7384e-04 - val_mse: 3.4767e-04\n",
            "Epoch 341/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.8787e-04 - mse: 7.7574e-04\n",
            "Epoch 341: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.1497e-04 - mse: 8.2994e-04 - val_loss: 1.7653e-04 - val_mse: 3.5307e-04\n",
            "Epoch 342/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 4.1796e-04 - mse: 8.3592e-04\n",
            "Epoch 342: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 4.1455e-04 - mse: 8.2910e-04 - val_loss: 1.8324e-04 - val_mse: 3.6647e-04\n",
            "Epoch 343/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 4.1491e-04 - mse: 8.2983e-04\n",
            "Epoch 343: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.3907e-04 - mse: 8.7814e-04 - val_loss: 1.9935e-04 - val_mse: 3.9871e-04\n",
            "Epoch 344/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.9038e-04 - mse: 7.8077e-04\n",
            "Epoch 344: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.9449e-04 - mse: 7.8898e-04 - val_loss: 1.7358e-04 - val_mse: 3.4716e-04\n",
            "Epoch 345/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.0560e-04 - mse: 8.1120e-04\n",
            "Epoch 345: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3.8289e-04 - mse: 7.6578e-04 - val_loss: 1.8956e-04 - val_mse: 3.7912e-04\n",
            "Epoch 346/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.6112e-04 - mse: 7.2224e-04\n",
            "Epoch 346: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.7298e-04 - mse: 7.4595e-04 - val_loss: 1.8736e-04 - val_mse: 3.7471e-04\n",
            "Epoch 347/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.5647e-04 - mse: 7.1294e-04\n",
            "Epoch 347: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.5725e-04 - mse: 7.1450e-04 - val_loss: 1.8062e-04 - val_mse: 3.6123e-04\n",
            "Epoch 348/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.3592e-04 - mse: 6.7184e-04\n",
            "Epoch 348: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.6446e-04 - mse: 7.2891e-04 - val_loss: 2.0964e-04 - val_mse: 4.1928e-04\n",
            "Epoch 349/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 4.2340e-04 - mse: 8.4680e-04\n",
            "Epoch 349: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.9113e-04 - mse: 7.8226e-04 - val_loss: 1.8489e-04 - val_mse: 3.6979e-04\n",
            "Epoch 350/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.6454e-04 - mse: 7.2909e-04\n",
            "Epoch 350: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 3.6326e-04 - mse: 7.2653e-04 - val_loss: 1.7512e-04 - val_mse: 3.5024e-04\n",
            "Epoch 351/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.5047e-04 - mse: 7.0095e-04\n",
            "Epoch 351: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 3.7652e-04 - mse: 7.5304e-04 - val_loss: 1.7477e-04 - val_mse: 3.4953e-04\n",
            "Epoch 352/2000\n",
            " 6/12 [==============>...............] - ETA: 0s - loss: 3.9294e-04 - mse: 7.8587e-04\n",
            "Epoch 352: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 3.5186e-04 - mse: 7.0371e-04 - val_loss: 2.0909e-04 - val_mse: 4.1817e-04\n",
            "Epoch 353/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 3.5639e-04 - mse: 7.1278e-04\n",
            "Epoch 353: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 3.6840e-04 - mse: 7.3681e-04 - val_loss: 2.2939e-04 - val_mse: 4.5878e-04\n",
            "Epoch 354/2000\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.8549e-04 - mse: 7.7097e-04\n",
            "Epoch 354: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 3.8549e-04 - mse: 7.7097e-04 - val_loss: 2.1756e-04 - val_mse: 4.3513e-04\n",
            "Epoch 355/2000\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.5306e-04 - mse: 7.0612e-04\n",
            "Epoch 355: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 3.5306e-04 - mse: 7.0612e-04 - val_loss: 2.3912e-04 - val_mse: 4.7824e-04\n",
            "Epoch 356/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 3.9014e-04 - mse: 7.8029e-04\n",
            "Epoch 356: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 4.2065e-04 - mse: 8.4130e-04 - val_loss: 2.0820e-04 - val_mse: 4.1640e-04\n",
            "Epoch 357/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 4.6072e-04 - mse: 9.2144e-04\n",
            "Epoch 357: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 4.6521e-04 - mse: 9.3041e-04 - val_loss: 2.3111e-04 - val_mse: 4.6221e-04\n",
            "Epoch 358/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 3.9153e-04 - mse: 7.8306e-04\n",
            "Epoch 358: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 3.7948e-04 - mse: 7.5896e-04 - val_loss: 1.8777e-04 - val_mse: 3.7553e-04\n",
            "Epoch 359/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 2.9380e-04 - mse: 5.8760e-04\n",
            "Epoch 359: val_loss improved from 0.00017 to 0.00017, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 3.4700e-04 - mse: 6.9400e-04 - val_loss: 1.7158e-04 - val_mse: 3.4315e-04\n",
            "Epoch 360/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.2187e-04 - mse: 6.4375e-04\n",
            "Epoch 360: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 3.5641e-04 - mse: 7.1281e-04 - val_loss: 1.8116e-04 - val_mse: 3.6231e-04\n",
            "Epoch 361/2000\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.5566e-04 - mse: 7.1132e-04\n",
            "Epoch 361: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 3.5566e-04 - mse: 7.1132e-04 - val_loss: 1.7983e-04 - val_mse: 3.5966e-04\n",
            "Epoch 362/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.2422e-04 - mse: 6.4843e-04\n",
            "Epoch 362: val_loss improved from 0.00017 to 0.00017, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 3.6409e-04 - mse: 7.2818e-04 - val_loss: 1.7146e-04 - val_mse: 3.4293e-04\n",
            "Epoch 363/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.8077e-04 - mse: 7.6153e-04\n",
            "Epoch 363: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.7962e-04 - mse: 7.5924e-04 - val_loss: 1.7423e-04 - val_mse: 3.4845e-04\n",
            "Epoch 364/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.7344e-04 - mse: 7.4687e-04\n",
            "Epoch 364: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.5042e-04 - mse: 7.0084e-04 - val_loss: 2.2043e-04 - val_mse: 4.4086e-04\n",
            "Epoch 365/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.6345e-04 - mse: 7.2691e-04\n",
            "Epoch 365: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.6290e-04 - mse: 7.2581e-04 - val_loss: 1.9311e-04 - val_mse: 3.8622e-04\n",
            "Epoch 366/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.4160e-04 - mse: 6.8319e-04\n",
            "Epoch 366: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.5906e-04 - mse: 7.1813e-04 - val_loss: 2.0566e-04 - val_mse: 4.1132e-04\n",
            "Epoch 367/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.9640e-04 - mse: 7.9279e-04\n",
            "Epoch 367: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.7000e-04 - mse: 7.4000e-04 - val_loss: 2.2493e-04 - val_mse: 4.4986e-04\n",
            "Epoch 368/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.9171e-04 - mse: 7.8342e-04\n",
            "Epoch 368: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.9793e-04 - mse: 7.9587e-04 - val_loss: 2.7376e-04 - val_mse: 5.4752e-04\n",
            "Epoch 369/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.8424e-04 - mse: 7.6847e-04\n",
            "Epoch 369: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.6911e-04 - mse: 7.3822e-04 - val_loss: 1.9648e-04 - val_mse: 3.9295e-04\n",
            "Epoch 370/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.3307e-04 - mse: 6.6613e-04\n",
            "Epoch 370: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.6721e-04 - mse: 7.3441e-04 - val_loss: 2.1168e-04 - val_mse: 4.2336e-04\n",
            "Epoch 371/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.2781e-04 - mse: 6.5561e-04\n",
            "Epoch 371: val_loss improved from 0.00017 to 0.00017, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 3.4586e-04 - mse: 6.9172e-04 - val_loss: 1.6877e-04 - val_mse: 3.3753e-04\n",
            "Epoch 372/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.7591e-04 - mse: 7.5182e-04\n",
            "Epoch 372: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3.5269e-04 - mse: 7.0539e-04 - val_loss: 1.7320e-04 - val_mse: 3.4641e-04\n",
            "Epoch 373/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.4205e-04 - mse: 6.8409e-04\n",
            "Epoch 373: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.5118e-04 - mse: 7.0236e-04 - val_loss: 1.6939e-04 - val_mse: 3.3879e-04\n",
            "Epoch 374/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 3.4854e-04 - mse: 6.9708e-04\n",
            "Epoch 374: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.5952e-04 - mse: 7.1905e-04 - val_loss: 1.7119e-04 - val_mse: 3.4237e-04\n",
            "Epoch 375/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.9513e-04 - mse: 7.9025e-04\n",
            "Epoch 375: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.7570e-04 - mse: 7.5139e-04 - val_loss: 1.6998e-04 - val_mse: 3.3997e-04\n",
            "Epoch 376/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.5623e-04 - mse: 7.1246e-04\n",
            "Epoch 376: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3.5287e-04 - mse: 7.0573e-04 - val_loss: 1.7008e-04 - val_mse: 3.4016e-04\n",
            "Epoch 377/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.9328e-04 - mse: 7.8656e-04\n",
            "Epoch 377: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.7975e-04 - mse: 7.5950e-04 - val_loss: 1.7982e-04 - val_mse: 3.5963e-04\n",
            "Epoch 378/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.5914e-04 - mse: 7.1827e-04\n",
            "Epoch 378: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.5396e-04 - mse: 7.0791e-04 - val_loss: 1.6922e-04 - val_mse: 3.3844e-04\n",
            "Epoch 379/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.8478e-04 - mse: 7.6956e-04\n",
            "Epoch 379: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.5480e-04 - mse: 7.0959e-04 - val_loss: 1.7479e-04 - val_mse: 3.4957e-04\n",
            "Epoch 380/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.5208e-04 - mse: 7.0417e-04\n",
            "Epoch 380: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.5192e-04 - mse: 7.0383e-04 - val_loss: 1.8119e-04 - val_mse: 3.6238e-04\n",
            "Epoch 381/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.6271e-04 - mse: 7.2542e-04\n",
            "Epoch 381: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.4791e-04 - mse: 6.9581e-04 - val_loss: 1.8370e-04 - val_mse: 3.6740e-04\n",
            "Epoch 382/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.4737e-04 - mse: 6.9473e-04\n",
            "Epoch 382: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3.4887e-04 - mse: 6.9774e-04 - val_loss: 1.7165e-04 - val_mse: 3.4329e-04\n",
            "Epoch 383/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.4626e-04 - mse: 6.9251e-04\n",
            "Epoch 383: val_loss improved from 0.00017 to 0.00017, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 3.4664e-04 - mse: 6.9327e-04 - val_loss: 1.6824e-04 - val_mse: 3.3649e-04\n",
            "Epoch 384/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.0538e-04 - mse: 6.1075e-04\n",
            "Epoch 384: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.6136e-04 - mse: 7.2272e-04 - val_loss: 1.7254e-04 - val_mse: 3.4508e-04\n",
            "Epoch 385/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 2.6896e-04 - mse: 5.3792e-04\n",
            "Epoch 385: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.5345e-04 - mse: 7.0691e-04 - val_loss: 1.6844e-04 - val_mse: 3.3688e-04\n",
            "Epoch 386/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.9125e-04 - mse: 7.8249e-04\n",
            "Epoch 386: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.5988e-04 - mse: 7.1977e-04 - val_loss: 1.7066e-04 - val_mse: 3.4132e-04\n",
            "Epoch 387/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.4545e-04 - mse: 6.9089e-04\n",
            "Epoch 387: val_loss improved from 0.00017 to 0.00017, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 3.5335e-04 - mse: 7.0671e-04 - val_loss: 1.6719e-04 - val_mse: 3.3437e-04\n",
            "Epoch 388/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.7898e-04 - mse: 7.5796e-04\n",
            "Epoch 388: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.5792e-04 - mse: 7.1585e-04 - val_loss: 1.8953e-04 - val_mse: 3.7906e-04\n",
            "Epoch 389/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.5797e-04 - mse: 7.1594e-04\n",
            "Epoch 389: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.6281e-04 - mse: 7.2562e-04 - val_loss: 1.6991e-04 - val_mse: 3.3983e-04\n",
            "Epoch 390/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.9458e-04 - mse: 7.8916e-04\n",
            "Epoch 390: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.7113e-04 - mse: 7.4226e-04 - val_loss: 1.7111e-04 - val_mse: 3.4222e-04\n",
            "Epoch 391/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.6532e-04 - mse: 7.3065e-04\n",
            "Epoch 391: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.7795e-04 - mse: 7.5589e-04 - val_loss: 1.9314e-04 - val_mse: 3.8627e-04\n",
            "Epoch 392/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.1471e-04 - mse: 6.2941e-04\n",
            "Epoch 392: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 3.4681e-04 - mse: 6.9362e-04 - val_loss: 1.7118e-04 - val_mse: 3.4237e-04\n",
            "Epoch 393/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.2926e-04 - mse: 6.5852e-04\n",
            "Epoch 393: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.5527e-04 - mse: 7.1053e-04 - val_loss: 1.7351e-04 - val_mse: 3.4701e-04\n",
            "Epoch 394/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.7053e-04 - mse: 7.4105e-04\n",
            "Epoch 394: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.6844e-04 - mse: 7.3688e-04 - val_loss: 1.7169e-04 - val_mse: 3.4338e-04\n",
            "Epoch 395/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.0173e-04 - mse: 8.0346e-04\n",
            "Epoch 395: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.8726e-04 - mse: 7.7452e-04 - val_loss: 1.6935e-04 - val_mse: 3.3871e-04\n",
            "Epoch 396/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.2926e-04 - mse: 6.5853e-04\n",
            "Epoch 396: val_loss improved from 0.00017 to 0.00017, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 3.4643e-04 - mse: 6.9287e-04 - val_loss: 1.6610e-04 - val_mse: 3.3219e-04\n",
            "Epoch 397/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.6317e-04 - mse: 7.2634e-04\n",
            "Epoch 397: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.8292e-04 - mse: 7.6584e-04 - val_loss: 1.6656e-04 - val_mse: 3.3312e-04\n",
            "Epoch 398/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.4033e-04 - mse: 6.8066e-04\n",
            "Epoch 398: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.4870e-04 - mse: 6.9741e-04 - val_loss: 1.6937e-04 - val_mse: 3.3874e-04\n",
            "Epoch 399/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.4470e-04 - mse: 6.8940e-04\n",
            "Epoch 399: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.4289e-04 - mse: 6.8579e-04 - val_loss: 1.9617e-04 - val_mse: 3.9234e-04\n",
            "Epoch 400/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.9356e-04 - mse: 7.8711e-04\n",
            "Epoch 400: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 3.4853e-04 - mse: 6.9706e-04 - val_loss: 1.8563e-04 - val_mse: 3.7126e-04\n",
            "Epoch 401/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 2.6417e-04 - mse: 5.2834e-04\n",
            "Epoch 401: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.4514e-04 - mse: 6.9028e-04 - val_loss: 1.8399e-04 - val_mse: 3.6797e-04\n",
            "Epoch 402/2000\n",
            "12/12 [==============================] - ETA: 0s - loss: 4.1701e-04 - mse: 8.3402e-04\n",
            "Epoch 402: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 4.1701e-04 - mse: 8.3402e-04 - val_loss: 1.7306e-04 - val_mse: 3.4611e-04\n",
            "Epoch 403/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 4.0449e-04 - mse: 8.0897e-04\n",
            "Epoch 403: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 3.7057e-04 - mse: 7.4114e-04 - val_loss: 1.6703e-04 - val_mse: 3.3407e-04\n",
            "Epoch 404/2000\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.4743e-04 - mse: 6.9487e-04\n",
            "Epoch 404: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 3.4743e-04 - mse: 6.9487e-04 - val_loss: 1.6939e-04 - val_mse: 3.3878e-04\n",
            "Epoch 405/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.2873e-04 - mse: 6.5747e-04\n",
            "Epoch 405: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 3.4729e-04 - mse: 6.9458e-04 - val_loss: 1.8266e-04 - val_mse: 3.6533e-04\n",
            "Epoch 406/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 2.7244e-04 - mse: 5.4487e-04\n",
            "Epoch 406: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 3.6191e-04 - mse: 7.2381e-04 - val_loss: 1.7212e-04 - val_mse: 3.4424e-04\n",
            "Epoch 407/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.2331e-04 - mse: 6.4662e-04\n",
            "Epoch 407: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 3.3717e-04 - mse: 6.7433e-04 - val_loss: 2.4559e-04 - val_mse: 4.9117e-04\n",
            "Epoch 408/2000\n",
            " 6/12 [==============>...............] - ETA: 0s - loss: 3.6609e-04 - mse: 7.3218e-04\n",
            "Epoch 408: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 3.7867e-04 - mse: 7.5735e-04 - val_loss: 2.2209e-04 - val_mse: 4.4418e-04\n",
            "Epoch 409/2000\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.5541e-04 - mse: 7.1082e-04\n",
            "Epoch 409: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 3.5541e-04 - mse: 7.1082e-04 - val_loss: 1.7651e-04 - val_mse: 3.5302e-04\n",
            "Epoch 410/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 3.4633e-04 - mse: 6.9266e-04\n",
            "Epoch 410: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 3.4186e-04 - mse: 6.8371e-04 - val_loss: 1.8210e-04 - val_mse: 3.6420e-04\n",
            "Epoch 411/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 3.5589e-04 - mse: 7.1178e-04\n",
            "Epoch 411: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 3.6773e-04 - mse: 7.3546e-04 - val_loss: 2.4823e-04 - val_mse: 4.9647e-04\n",
            "Epoch 412/2000\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.6441e-04 - mse: 7.2881e-04\n",
            "Epoch 412: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 3.6441e-04 - mse: 7.2881e-04 - val_loss: 1.8843e-04 - val_mse: 3.7687e-04\n",
            "Epoch 413/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 3.3030e-04 - mse: 6.6060e-04\n",
            "Epoch 413: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 3.4611e-04 - mse: 6.9222e-04 - val_loss: 1.6818e-04 - val_mse: 3.3636e-04\n",
            "Epoch 414/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.6127e-04 - mse: 7.2255e-04\n",
            "Epoch 414: val_loss improved from 0.00017 to 0.00017, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 3.5193e-04 - mse: 7.0386e-04 - val_loss: 1.6577e-04 - val_mse: 3.3154e-04\n",
            "Epoch 415/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.4302e-04 - mse: 6.8604e-04\n",
            "Epoch 415: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.5495e-04 - mse: 7.0990e-04 - val_loss: 1.8423e-04 - val_mse: 3.6846e-04\n",
            "Epoch 416/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.6198e-04 - mse: 7.2396e-04\n",
            "Epoch 416: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.6561e-04 - mse: 7.3122e-04 - val_loss: 1.6720e-04 - val_mse: 3.3440e-04\n",
            "Epoch 417/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.3233e-04 - mse: 6.6466e-04\n",
            "Epoch 417: val_loss did not improve from 0.00017\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.4937e-04 - mse: 6.9873e-04 - val_loss: 1.6647e-04 - val_mse: 3.3294e-04\n",
            "Epoch 418/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.6731e-04 - mse: 7.3462e-04\n",
            "Epoch 418: val_loss improved from 0.00017 to 0.00016, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 3.5527e-04 - mse: 7.1054e-04 - val_loss: 1.6370e-04 - val_mse: 3.2739e-04\n",
            "Epoch 419/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.4086e-04 - mse: 6.8172e-04\n",
            "Epoch 419: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.5320e-04 - mse: 7.0640e-04 - val_loss: 1.6555e-04 - val_mse: 3.3110e-04\n",
            "Epoch 420/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.0605e-04 - mse: 6.1209e-04\n",
            "Epoch 420: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.4313e-04 - mse: 6.8627e-04 - val_loss: 1.6537e-04 - val_mse: 3.3074e-04\n",
            "Epoch 421/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 3.4803e-04 - mse: 6.9606e-04\n",
            "Epoch 421: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.5657e-04 - mse: 7.1313e-04 - val_loss: 1.7263e-04 - val_mse: 3.4527e-04\n",
            "Epoch 422/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.0530e-04 - mse: 6.1060e-04\n",
            "Epoch 422: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.5814e-04 - mse: 7.1628e-04 - val_loss: 1.6518e-04 - val_mse: 3.3036e-04\n",
            "Epoch 423/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 3.8667e-04 - mse: 7.7334e-04\n",
            "Epoch 423: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 3.8111e-04 - mse: 7.6223e-04 - val_loss: 1.7430e-04 - val_mse: 3.4859e-04\n",
            "Epoch 424/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.3754e-04 - mse: 6.7509e-04\n",
            "Epoch 424: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.6352e-04 - mse: 7.2704e-04 - val_loss: 1.7188e-04 - val_mse: 3.4376e-04\n",
            "Epoch 425/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.9876e-04 - mse: 7.9752e-04\n",
            "Epoch 425: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3.9324e-04 - mse: 7.8648e-04 - val_loss: 1.6554e-04 - val_mse: 3.3109e-04\n",
            "Epoch 426/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.7950e-04 - mse: 7.5900e-04\n",
            "Epoch 426: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3.8271e-04 - mse: 7.6542e-04 - val_loss: 2.1433e-04 - val_mse: 4.2866e-04\n",
            "Epoch 427/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.6320e-04 - mse: 7.2640e-04\n",
            "Epoch 427: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.4723e-04 - mse: 6.9446e-04 - val_loss: 1.6738e-04 - val_mse: 3.3476e-04\n",
            "Epoch 428/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.4519e-04 - mse: 6.9038e-04\n",
            "Epoch 428: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.5581e-04 - mse: 7.1162e-04 - val_loss: 2.0267e-04 - val_mse: 4.0534e-04\n",
            "Epoch 429/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.0517e-04 - mse: 8.1034e-04\n",
            "Epoch 429: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 3.8932e-04 - mse: 7.7865e-04 - val_loss: 2.0633e-04 - val_mse: 4.1265e-04\n",
            "Epoch 430/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.9835e-04 - mse: 7.9671e-04\n",
            "Epoch 430: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.7004e-04 - mse: 7.4008e-04 - val_loss: 2.5745e-04 - val_mse: 5.1489e-04\n",
            "Epoch 431/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 4.1406e-04 - mse: 8.2812e-04\n",
            "Epoch 431: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.7919e-04 - mse: 7.5838e-04 - val_loss: 1.8195e-04 - val_mse: 3.6389e-04\n",
            "Epoch 432/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 2.7455e-04 - mse: 5.4909e-04\n",
            "Epoch 432: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.4124e-04 - mse: 6.8248e-04 - val_loss: 1.6596e-04 - val_mse: 3.3191e-04\n",
            "Epoch 433/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.7308e-04 - mse: 7.4616e-04\n",
            "Epoch 433: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.8745e-04 - mse: 7.7491e-04 - val_loss: 1.6977e-04 - val_mse: 3.3953e-04\n",
            "Epoch 434/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.9668e-04 - mse: 7.9335e-04\n",
            "Epoch 434: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.9390e-04 - mse: 7.8780e-04 - val_loss: 1.8872e-04 - val_mse: 3.7743e-04\n",
            "Epoch 435/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.3270e-04 - mse: 6.6539e-04\n",
            "Epoch 435: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.5830e-04 - mse: 7.1660e-04 - val_loss: 1.6855e-04 - val_mse: 3.3709e-04\n",
            "Epoch 436/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.7368e-04 - mse: 7.4737e-04\n",
            "Epoch 436: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 3.7007e-04 - mse: 7.4015e-04 - val_loss: 2.0564e-04 - val_mse: 4.1129e-04\n",
            "Epoch 437/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 4.4096e-04 - mse: 8.8192e-04\n",
            "Epoch 437: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.7133e-04 - mse: 7.4266e-04 - val_loss: 1.8694e-04 - val_mse: 3.7388e-04\n",
            "Epoch 438/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.9741e-04 - mse: 7.9482e-04\n",
            "Epoch 438: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.4990e-04 - mse: 6.9979e-04 - val_loss: 2.1057e-04 - val_mse: 4.2113e-04\n",
            "Epoch 439/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.4321e-04 - mse: 6.8643e-04\n",
            "Epoch 439: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.5733e-04 - mse: 7.1466e-04 - val_loss: 2.1539e-04 - val_mse: 4.3078e-04\n",
            "Epoch 440/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.7832e-04 - mse: 7.5665e-04\n",
            "Epoch 440: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.8819e-04 - mse: 7.7638e-04 - val_loss: 1.8722e-04 - val_mse: 3.7444e-04\n",
            "Epoch 441/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.4665e-04 - mse: 6.9331e-04\n",
            "Epoch 441: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 3.8856e-04 - mse: 7.7712e-04 - val_loss: 1.6419e-04 - val_mse: 3.2837e-04\n",
            "Epoch 442/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.3710e-04 - mse: 6.7419e-04\n",
            "Epoch 442: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.4136e-04 - mse: 6.8271e-04 - val_loss: 1.8207e-04 - val_mse: 3.6413e-04\n",
            "Epoch 443/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.6244e-04 - mse: 7.2488e-04\n",
            "Epoch 443: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.3590e-04 - mse: 6.7180e-04 - val_loss: 1.6637e-04 - val_mse: 3.3274e-04\n",
            "Epoch 444/2000\n",
            " 6/12 [==============>...............] - ETA: 0s - loss: 3.6089e-04 - mse: 7.2177e-04\n",
            "Epoch 444: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 3.3792e-04 - mse: 6.7583e-04 - val_loss: 1.7512e-04 - val_mse: 3.5025e-04\n",
            "Epoch 445/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.2423e-04 - mse: 6.4846e-04\n",
            "Epoch 445: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.3841e-04 - mse: 6.7682e-04 - val_loss: 1.6980e-04 - val_mse: 3.3960e-04\n",
            "Epoch 446/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.2908e-04 - mse: 6.5816e-04\n",
            "Epoch 446: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.4210e-04 - mse: 6.8421e-04 - val_loss: 1.7432e-04 - val_mse: 3.4864e-04\n",
            "Epoch 447/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.3949e-04 - mse: 6.7898e-04\n",
            "Epoch 447: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.4332e-04 - mse: 6.8665e-04 - val_loss: 1.6376e-04 - val_mse: 3.2751e-04\n",
            "Epoch 448/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.5838e-04 - mse: 7.1677e-04\n",
            "Epoch 448: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 3.3858e-04 - mse: 6.7716e-04 - val_loss: 1.6477e-04 - val_mse: 3.2954e-04\n",
            "Epoch 449/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.5267e-04 - mse: 7.0535e-04\n",
            "Epoch 449: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.4385e-04 - mse: 6.8769e-04 - val_loss: 1.6478e-04 - val_mse: 3.2956e-04\n",
            "Epoch 450/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.7042e-04 - mse: 7.4083e-04\n",
            "Epoch 450: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.7406e-04 - mse: 7.4811e-04 - val_loss: 1.7298e-04 - val_mse: 3.4597e-04\n",
            "Epoch 451/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.4053e-04 - mse: 6.8106e-04\n",
            "Epoch 451: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 3.5740e-04 - mse: 7.1480e-04 - val_loss: 1.7683e-04 - val_mse: 3.5366e-04\n",
            "Epoch 452/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.6369e-04 - mse: 7.2737e-04\n",
            "Epoch 452: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.6001e-04 - mse: 7.2001e-04 - val_loss: 1.6917e-04 - val_mse: 3.3834e-04\n",
            "Epoch 453/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.4742e-04 - mse: 6.9483e-04\n",
            "Epoch 453: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.4799e-04 - mse: 6.9597e-04 - val_loss: 1.6413e-04 - val_mse: 3.2826e-04\n",
            "Epoch 454/2000\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.5122e-04 - mse: 7.0243e-04\n",
            "Epoch 454: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 3.5122e-04 - mse: 7.0243e-04 - val_loss: 1.7620e-04 - val_mse: 3.5239e-04\n",
            "Epoch 455/2000\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.5437e-04 - mse: 7.0873e-04\n",
            "Epoch 455: val_loss improved from 0.00016 to 0.00016, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 3.5437e-04 - mse: 7.0873e-04 - val_loss: 1.6197e-04 - val_mse: 3.2393e-04\n",
            "Epoch 456/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 3.9200e-04 - mse: 7.8401e-04\n",
            "Epoch 456: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 3.8353e-04 - mse: 7.6705e-04 - val_loss: 1.9908e-04 - val_mse: 3.9817e-04\n",
            "Epoch 457/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 4.1086e-04 - mse: 8.2171e-04\n",
            "Epoch 457: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 4.0966e-04 - mse: 8.1933e-04 - val_loss: 2.5506e-04 - val_mse: 5.1011e-04\n",
            "Epoch 458/2000\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.9183e-04 - mse: 7.8366e-04\n",
            "Epoch 458: val_loss improved from 0.00016 to 0.00016, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 3.9183e-04 - mse: 7.8366e-04 - val_loss: 1.6122e-04 - val_mse: 3.2245e-04\n",
            "Epoch 459/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 3.9306e-04 - mse: 7.8612e-04\n",
            "Epoch 459: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 3.4599e-04 - mse: 6.9199e-04 - val_loss: 1.8017e-04 - val_mse: 3.6033e-04\n",
            "Epoch 460/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 3.4961e-04 - mse: 6.9921e-04\n",
            "Epoch 460: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 3.3273e-04 - mse: 6.6545e-04 - val_loss: 1.8537e-04 - val_mse: 3.7073e-04\n",
            "Epoch 461/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.6244e-04 - mse: 7.2488e-04\n",
            "Epoch 461: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.5466e-04 - mse: 7.0932e-04 - val_loss: 1.6249e-04 - val_mse: 3.2497e-04\n",
            "Epoch 462/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 3.3458e-04 - mse: 6.6916e-04\n",
            "Epoch 462: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.7263e-04 - mse: 7.4526e-04 - val_loss: 1.6360e-04 - val_mse: 3.2719e-04\n",
            "Epoch 463/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.1845e-04 - mse: 6.3691e-04\n",
            "Epoch 463: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.5458e-04 - mse: 7.0915e-04 - val_loss: 1.6575e-04 - val_mse: 3.3150e-04\n",
            "Epoch 464/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 3.6069e-04 - mse: 7.2139e-04\n",
            "Epoch 464: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.4892e-04 - mse: 6.9783e-04 - val_loss: 1.7119e-04 - val_mse: 3.4237e-04\n",
            "Epoch 465/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.7587e-04 - mse: 7.5175e-04\n",
            "Epoch 465: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.4847e-04 - mse: 6.9694e-04 - val_loss: 1.6425e-04 - val_mse: 3.2849e-04\n",
            "Epoch 466/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.5546e-04 - mse: 7.1093e-04\n",
            "Epoch 466: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 3.5835e-04 - mse: 7.1670e-04 - val_loss: 1.6985e-04 - val_mse: 3.3969e-04\n",
            "Epoch 467/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 3.2982e-04 - mse: 6.5963e-04\n",
            "Epoch 467: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.6099e-04 - mse: 7.2198e-04 - val_loss: 1.6861e-04 - val_mse: 3.3723e-04\n",
            "Epoch 468/2000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 3.5811e-04 - mse: 7.1621e-04\n",
            "Epoch 468: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3.4713e-04 - mse: 6.9426e-04 - val_loss: 1.7561e-04 - val_mse: 3.5123e-04\n",
            "Epoch 469/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.3929e-04 - mse: 6.7858e-04\n",
            "Epoch 469: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.5268e-04 - mse: 7.0535e-04 - val_loss: 1.9820e-04 - val_mse: 3.9640e-04\n",
            "Epoch 470/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.5739e-04 - mse: 7.1479e-04\n",
            "Epoch 470: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.6968e-04 - mse: 7.3936e-04 - val_loss: 1.6412e-04 - val_mse: 3.2825e-04\n",
            "Epoch 471/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.3557e-04 - mse: 6.7115e-04\n",
            "Epoch 471: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.7031e-04 - mse: 7.4062e-04 - val_loss: 1.6533e-04 - val_mse: 3.3066e-04\n",
            "Epoch 472/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.1080e-04 - mse: 6.2160e-04\n",
            "Epoch 472: val_loss improved from 0.00016 to 0.00016, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 3.5322e-04 - mse: 7.0644e-04 - val_loss: 1.6050e-04 - val_mse: 3.2099e-04\n",
            "Epoch 473/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.2483e-04 - mse: 6.4967e-04\n",
            "Epoch 473: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.4217e-04 - mse: 6.8434e-04 - val_loss: 1.6233e-04 - val_mse: 3.2467e-04\n",
            "Epoch 474/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.5340e-04 - mse: 7.0680e-04\n",
            "Epoch 474: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.5121e-04 - mse: 7.0242e-04 - val_loss: 1.6255e-04 - val_mse: 3.2510e-04\n",
            "Epoch 475/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.3536e-04 - mse: 6.7072e-04\n",
            "Epoch 475: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.5084e-04 - mse: 7.0168e-04 - val_loss: 1.7564e-04 - val_mse: 3.5128e-04\n",
            "Epoch 476/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.8300e-04 - mse: 7.6600e-04\n",
            "Epoch 476: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3.9546e-04 - mse: 7.9092e-04 - val_loss: 1.7628e-04 - val_mse: 3.5256e-04\n",
            "Epoch 477/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.0997e-04 - mse: 8.1995e-04\n",
            "Epoch 477: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 3.9445e-04 - mse: 7.8890e-04 - val_loss: 2.0890e-04 - val_mse: 4.1779e-04\n",
            "Epoch 478/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.2588e-04 - mse: 8.5176e-04\n",
            "Epoch 478: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 4.0821e-04 - mse: 8.1642e-04 - val_loss: 1.6520e-04 - val_mse: 3.3040e-04\n",
            "Epoch 479/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.6100e-04 - mse: 7.2200e-04\n",
            "Epoch 479: val_loss improved from 0.00016 to 0.00016, saving model to tmp/ckeckpointer.ckpt\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 3.5872e-04 - mse: 7.1744e-04 - val_loss: 1.5885e-04 - val_mse: 3.1771e-04\n",
            "Epoch 480/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.9498e-04 - mse: 7.8996e-04\n",
            "Epoch 480: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.6469e-04 - mse: 7.2937e-04 - val_loss: 1.6609e-04 - val_mse: 3.3219e-04\n",
            "Epoch 481/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.2164e-04 - mse: 6.4328e-04\n",
            "Epoch 481: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.4686e-04 - mse: 6.9371e-04 - val_loss: 1.6325e-04 - val_mse: 3.2651e-04\n",
            "Epoch 482/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.2057e-04 - mse: 6.4114e-04\n",
            "Epoch 482: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.3889e-04 - mse: 6.7777e-04 - val_loss: 1.6614e-04 - val_mse: 3.3229e-04\n",
            "Epoch 483/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.7439e-04 - mse: 7.4878e-04\n",
            "Epoch 483: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.4463e-04 - mse: 6.8927e-04 - val_loss: 1.7309e-04 - val_mse: 3.4618e-04\n",
            "Epoch 484/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 4.5006e-04 - mse: 9.0012e-04\n",
            "Epoch 484: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.2305e-04 - mse: 8.4609e-04 - val_loss: 1.7771e-04 - val_mse: 3.5542e-04\n",
            "Epoch 485/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.1425e-04 - mse: 8.2849e-04\n",
            "Epoch 485: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.0578e-04 - mse: 8.1156e-04 - val_loss: 1.9889e-04 - val_mse: 3.9777e-04\n",
            "Epoch 486/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.1518e-04 - mse: 8.3036e-04\n",
            "Epoch 486: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.1331e-04 - mse: 8.2661e-04 - val_loss: 1.6985e-04 - val_mse: 3.3970e-04\n",
            "Epoch 487/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.8076e-04 - mse: 7.6153e-04\n",
            "Epoch 487: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.5933e-04 - mse: 7.1866e-04 - val_loss: 1.6801e-04 - val_mse: 3.3602e-04\n",
            "Epoch 488/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.7902e-04 - mse: 7.5804e-04\n",
            "Epoch 488: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.3942e-04 - mse: 6.7885e-04 - val_loss: 1.9265e-04 - val_mse: 3.8530e-04\n",
            "Epoch 489/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.6286e-04 - mse: 7.2571e-04\n",
            "Epoch 489: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.4536e-04 - mse: 6.9072e-04 - val_loss: 1.9561e-04 - val_mse: 3.9122e-04\n",
            "Epoch 490/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.5177e-04 - mse: 7.0353e-04\n",
            "Epoch 490: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.6476e-04 - mse: 7.2951e-04 - val_loss: 1.8480e-04 - val_mse: 3.6960e-04\n",
            "Epoch 491/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.2840e-04 - mse: 8.5680e-04\n",
            "Epoch 491: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.1332e-04 - mse: 8.2664e-04 - val_loss: 2.0296e-04 - val_mse: 4.0591e-04\n",
            "Epoch 492/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 4.1363e-04 - mse: 8.2725e-04\n",
            "Epoch 492: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.2159e-04 - mse: 8.4318e-04 - val_loss: 1.8719e-04 - val_mse: 3.7438e-04\n",
            "Epoch 493/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.9240e-04 - mse: 7.8480e-04\n",
            "Epoch 493: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.6590e-04 - mse: 7.3180e-04 - val_loss: 1.6316e-04 - val_mse: 3.2632e-04\n",
            "Epoch 494/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.5905e-04 - mse: 7.1810e-04\n",
            "Epoch 494: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.4483e-04 - mse: 6.8966e-04 - val_loss: 2.2062e-04 - val_mse: 4.4125e-04\n",
            "Epoch 495/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.4701e-04 - mse: 8.9402e-04\n",
            "Epoch 495: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 4.3380e-04 - mse: 8.6761e-04 - val_loss: 2.3280e-04 - val_mse: 4.6559e-04\n",
            "Epoch 496/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.6815e-04 - mse: 7.3630e-04\n",
            "Epoch 496: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.9041e-04 - mse: 7.8082e-04 - val_loss: 2.6145e-04 - val_mse: 5.2290e-04\n",
            "Epoch 497/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.8817e-04 - mse: 7.7633e-04\n",
            "Epoch 497: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.0985e-04 - mse: 8.1971e-04 - val_loss: 2.5253e-04 - val_mse: 5.0507e-04\n",
            "Epoch 498/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 4.1083e-04 - mse: 8.2167e-04\n",
            "Epoch 498: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.7265e-04 - mse: 7.4531e-04 - val_loss: 1.8060e-04 - val_mse: 3.6119e-04\n",
            "Epoch 499/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.5299e-04 - mse: 7.0599e-04\n",
            "Epoch 499: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 3.4138e-04 - mse: 6.8276e-04 - val_loss: 1.7153e-04 - val_mse: 3.4306e-04\n",
            "Epoch 500/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 2.8634e-04 - mse: 5.7267e-04\n",
            "Epoch 500: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.3611e-04 - mse: 6.7221e-04 - val_loss: 1.6287e-04 - val_mse: 3.2573e-04\n",
            "Epoch 501/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.0592e-04 - mse: 6.1184e-04\n",
            "Epoch 501: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.4074e-04 - mse: 6.8148e-04 - val_loss: 1.6578e-04 - val_mse: 3.3157e-04\n",
            "Epoch 502/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 3.7745e-04 - mse: 7.5490e-04\n",
            "Epoch 502: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 3.5734e-04 - mse: 7.1467e-04 - val_loss: 2.3514e-04 - val_mse: 4.7028e-04\n",
            "Epoch 503/2000\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.5743e-04 - mse: 7.1486e-04\n",
            "Epoch 503: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 3.5743e-04 - mse: 7.1486e-04 - val_loss: 2.5374e-04 - val_mse: 5.0747e-04\n",
            "Epoch 504/2000\n",
            " 6/12 [==============>...............] - ETA: 0s - loss: 5.1187e-04 - mse: 0.0010\n",
            "Epoch 504: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 4.2167e-04 - mse: 8.4334e-04 - val_loss: 1.8603e-04 - val_mse: 3.7206e-04\n",
            "Epoch 505/2000\n",
            " 6/12 [==============>...............] - ETA: 0s - loss: 3.4235e-04 - mse: 6.8470e-04\n",
            "Epoch 505: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 3.6319e-04 - mse: 7.2639e-04 - val_loss: 2.1193e-04 - val_mse: 4.2385e-04\n",
            "Epoch 506/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.7363e-04 - mse: 7.4727e-04\n",
            "Epoch 506: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 3.5009e-04 - mse: 7.0017e-04 - val_loss: 2.0074e-04 - val_mse: 4.0149e-04\n",
            "Epoch 507/2000\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.4532e-04 - mse: 6.9064e-04\n",
            "Epoch 507: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 3.4532e-04 - mse: 6.9064e-04 - val_loss: 1.6584e-04 - val_mse: 3.3167e-04\n",
            "Epoch 508/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.5330e-04 - mse: 7.0659e-04\n",
            "Epoch 508: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 3.6697e-04 - mse: 7.3394e-04 - val_loss: 1.6171e-04 - val_mse: 3.2343e-04\n",
            "Epoch 509/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.5010e-04 - mse: 7.0020e-04\n",
            "Epoch 509: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 3.3669e-04 - mse: 6.7339e-04 - val_loss: 1.6363e-04 - val_mse: 3.2725e-04\n",
            "Epoch 510/2000\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.4756e-04 - mse: 6.9512e-04\n",
            "Epoch 510: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 3.4756e-04 - mse: 6.9512e-04 - val_loss: 1.8401e-04 - val_mse: 3.6803e-04\n",
            "Epoch 511/2000\n",
            "12/12 [==============================] - ETA: 0s - loss: 3.3595e-04 - mse: 6.7190e-04\n",
            "Epoch 511: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 3.3595e-04 - mse: 6.7190e-04 - val_loss: 1.6366e-04 - val_mse: 3.2732e-04\n",
            "Epoch 512/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.6578e-04 - mse: 7.3156e-04\n",
            "Epoch 512: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.5603e-04 - mse: 7.1207e-04 - val_loss: 1.8581e-04 - val_mse: 3.7161e-04\n",
            "Epoch 513/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.6697e-04 - mse: 7.3395e-04\n",
            "Epoch 513: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.7483e-04 - mse: 7.4966e-04 - val_loss: 1.6345e-04 - val_mse: 3.2690e-04\n",
            "Epoch 514/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.5963e-04 - mse: 7.1926e-04\n",
            "Epoch 514: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3.7394e-04 - mse: 7.4789e-04 - val_loss: 1.7538e-04 - val_mse: 3.5076e-04\n",
            "Epoch 515/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.8775e-04 - mse: 7.7550e-04\n",
            "Epoch 515: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.7531e-04 - mse: 7.5063e-04 - val_loss: 1.6232e-04 - val_mse: 3.2464e-04\n",
            "Epoch 516/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.2205e-04 - mse: 6.4410e-04\n",
            "Epoch 516: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.3497e-04 - mse: 6.6995e-04 - val_loss: 2.0313e-04 - val_mse: 4.0627e-04\n",
            "Epoch 517/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.2697e-04 - mse: 6.5394e-04\n",
            "Epoch 517: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.3750e-04 - mse: 6.7499e-04 - val_loss: 1.6091e-04 - val_mse: 3.2183e-04\n",
            "Epoch 518/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.5615e-04 - mse: 7.1230e-04\n",
            "Epoch 518: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.3792e-04 - mse: 6.7583e-04 - val_loss: 1.6501e-04 - val_mse: 3.3003e-04\n",
            "Epoch 519/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.4494e-04 - mse: 6.8987e-04\n",
            "Epoch 519: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.3488e-04 - mse: 6.6976e-04 - val_loss: 1.6755e-04 - val_mse: 3.3509e-04\n",
            "Epoch 520/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.5012e-04 - mse: 7.0025e-04\n",
            "Epoch 520: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.4145e-04 - mse: 6.8291e-04 - val_loss: 1.6498e-04 - val_mse: 3.2996e-04\n",
            "Epoch 521/2000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 3.2854e-04 - mse: 6.5708e-04\n",
            "Epoch 521: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.4873e-04 - mse: 6.9746e-04 - val_loss: 1.6512e-04 - val_mse: 3.3024e-04\n",
            "Epoch 522/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.2191e-04 - mse: 6.4381e-04\n",
            "Epoch 522: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.3969e-04 - mse: 6.7937e-04 - val_loss: 1.6086e-04 - val_mse: 3.2173e-04\n",
            "Epoch 523/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.2280e-04 - mse: 6.4559e-04\n",
            "Epoch 523: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.4034e-04 - mse: 6.8068e-04 - val_loss: 1.5957e-04 - val_mse: 3.1913e-04\n",
            "Epoch 524/2000\n",
            " 7/12 [================>.............] - ETA: 0s - loss: 3.1422e-04 - mse: 6.2845e-04\n",
            "Epoch 524: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.4598e-04 - mse: 6.9196e-04 - val_loss: 1.6035e-04 - val_mse: 3.2070e-04\n",
            "Epoch 525/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.2863e-04 - mse: 6.5726e-04\n",
            "Epoch 525: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.7776e-04 - mse: 7.5552e-04 - val_loss: 1.6185e-04 - val_mse: 3.2369e-04\n",
            "Epoch 526/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.9636e-04 - mse: 7.9272e-04\n",
            "Epoch 526: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.9112e-04 - mse: 7.8223e-04 - val_loss: 1.6647e-04 - val_mse: 3.3294e-04\n",
            "Epoch 527/2000\n",
            " 9/12 [=====================>........] - ETA: 0s - loss: 3.5885e-04 - mse: 7.1770e-04\n",
            "Epoch 527: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.7130e-04 - mse: 7.4260e-04 - val_loss: 1.6233e-04 - val_mse: 3.2465e-04\n",
            "Epoch 528/2000\n",
            " 6/12 [==============>...............] - ETA: 0s - loss: 3.4452e-04 - mse: 6.8905e-04\n",
            "Epoch 528: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 3.5311e-04 - mse: 7.0623e-04 - val_loss: 1.6099e-04 - val_mse: 3.2198e-04\n",
            "Epoch 529/2000\n",
            " 8/12 [===================>..........] - ETA: 0s - loss: 3.4369e-04 - mse: 6.8737e-04\n",
            "Epoch 529: val_loss did not improve from 0.00016\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 3.5101e-04 - mse: 7.0201e-04 - val_loss: 1.6428e-04 - val_mse: 3.2856e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(filename)\n",
        "pred = model.predict(test_data)\n",
        "plt.figure(figsize=(12, 9))\n",
        "plt.plot(np.asarray(y_test)[20:], label='actual')\n",
        "plt.plot(pred, label='prediction')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "EnXf0YMjiIbf",
        "outputId": "34135e97-d35c-452d-d0ea-38bfe2b657c5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 18ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x900 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}