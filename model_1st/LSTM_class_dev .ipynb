{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM class Developed\n",
        "-----------------------------\n",
        "[feat] 7/16\n",
        "- ! to prevent overfitting use K-fold, validation split ! <- NEED TO DEVELOP\n",
        "- basical LSTM model => lstm dense need to doubled\n",
        "- not tested\n",
        "- without AOC, interest rate\n",
        "- bidirectional LSTM Model"
      ],
      "metadata": {
        "id": "Jl1xbFVCPtKO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "imorts & get datas\n",
        "------------"
      ],
      "metadata": {
        "id": "53a68bbqPzrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -U finance-datareader\n",
        "\n",
        "#%pip install FinanceDataReader"
      ],
      "metadata": {
        "id": "IyhvmWrGQ-rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pandas_datareader as pdr\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense ,LSTM, Dropout,Bidirectional\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from tensorflow import expand_dims\n",
        "from tensorflow.keras.losses import Huber\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from os.path import join\n",
        "from tensorflow import constant\n",
        "#import FinanceDataReader as fdr"
      ],
      "metadata": {
        "id": "bDqimijIQjdY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-_pxjz3BPYpb"
      },
      "outputs": [],
      "source": [
        "data=pd.read_csv('/content/drive/MyDrive/2023_1st_vac/KRX_DATA/train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prescaler\n",
        "def getAOC(data):\n",
        "  AOC = []\n",
        "  close = data['종가']\n",
        "  close_pre = close.shift(1)\n",
        "\n",
        "  AOC.append(0)\n",
        "\n",
        "  # aoc = (금일 종가 - 전일 종가) / 전일 종가\n",
        "  for i in range(1, len(close)):\n",
        "    aoc_value = ((close[i] - close_pre[i]) / close_pre[i]) * 100\n",
        "    AOC.append(aoc_value)\n",
        "\n",
        "  return AOC\n",
        "\n",
        "#sort data by \"종목명\"\n",
        "subject_Data=data.sort_values(by=\"종목명\",inplace=False)\n",
        "subject_Data.head()\n",
        "subject_Data.columns\n",
        "\n",
        "pv_s_data=pd.pivot_table(subject_Data,values=['거래량', '시가', '고가', '저가', '종가'],index=['종목코드','일자'])\n",
        "\n",
        "divided = pv_s_data.index.get_level_values('종목코드').unique()\n",
        "\n",
        "sliced_dataframes = []\n",
        "\n",
        "for i in divided:\n",
        "    sliced_data = pv_s_data.loc[i]\n",
        "    sliced_dataframe = sliced_data.reset_index()\n",
        "    sliced_dataframes.append(sliced_dataframe)"
      ],
      "metadata": {
        "id": "Xg6dg09IUovd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=sliced_dataframes\n",
        "data"
      ],
      "metadata": {
        "id": "M3hGkLVFVVHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xseyDtvDYM00",
        "outputId": "6d87565c-6fdb-406f-f50d-f84045fbea08"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(494, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM_Object():\n",
        "\n",
        "  def __init__(self,data):\n",
        "    #get sliced data\n",
        "    self.data=data\n",
        "\n",
        "  def modeling(self):\n",
        "\n",
        "    self.prescale()\n",
        "    self.model=Sequential()\n",
        "    #layers\n",
        "    self.model.add(LSTM(1024,return_sequences=True,input_shape=(self.x_train.shape[1], self.x_train.shape[2])))\n",
        "    self.model.add(LSTM(1024,return_sequences=True,input_shape=(self.x_train.shape[1], self.x_train.shape[2])))\n",
        "    self.model.add(Dropout(0.25))\n",
        "    self.model.add(LSTM(1024,return_sequences=True,input_shape=(self.x_train.shape[1], self.x_train.shape[2])))\n",
        "    self.model.add(LSTM(1024,return_sequences=True,input_shape=(self.x_train.shape[1], self.x_train.shape[2])))\n",
        "    self.model.add(Dropout(0.25))\n",
        "    self.model.add(LSTM(1024,return_sequences=True,input_shape=(self.x_train.shape[1], self.x_train.shape[2])))\n",
        "    #output layer\n",
        "    self.model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    self.filename = join('tmp', 'ckeckpointer.ckpt')\n",
        "    checkpoint = ModelCheckpoint(self.filename, save_weights_only=True, save_best_only=True,monitor='val_loss',verbose=1)\n",
        "\n",
        "    earlystopping = EarlyStopping(monitor='val_loss', patience=100)\n",
        "\n",
        "\n",
        "    self.model.compile(loss = 'binary_crossentropy', optimizer=Adam(learning_rate=0.001))\n",
        "    history=self.model.fit(self.x_train,self.y_train,epochs=1000,batch_size=128,validation_data=(self.x_train,self.y_train),shuffle=False,callbacks=[checkpoint, earlystopping])\n",
        "\n",
        "\n",
        "  def prescale(self):\n",
        "    x_scaler=MinMaxScaler()\n",
        "    y_scaler=MinMaxScaler()\n",
        "    self.data[['거래량', '고가', '시가', '저가']]=x_scaler.fit_transform(self.data[['거래량', '고가', '시가', '저가']])\n",
        "    self.data['종가']=y_scaler.fit_transform(self.data['종가'].values.reshape(-1,1))\n",
        "    x_data=self.data[['거래량', '고가', '시가', '저가']]\n",
        "    y_data=self.data['종가']\n",
        "    x_train,x_test,y_train,y_test=train_test_split(x_data,y_data,test_size=0.2)\n",
        "\n",
        "    ### reshape input datas()\n",
        "\n",
        "    input_dim = constant(2)\n",
        "    self.x_train=expand_dims(x_train,input_dim)\n",
        "    self.x_test=expand_dims(x_test,input_dim)\n",
        "    self.y_train=y_train\n",
        "    self.y_test=y_test\n",
        "\n",
        "  def ret_learning(self):\n",
        "    self.prescale()\n",
        "    self.modeling()\n",
        "    self.model.load_weights(self.filename)\n",
        "    pred = self.model.predict(self.x_test)\n",
        "    plt.figure(figsize=(12, 9))\n",
        "    plt.plot(np.asarray(self.y_test)[20:], label='actual')\n",
        "    plt.plot(pred, label='prediction')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "rqz4N2_IVacg"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_1=data[0]"
      ],
      "metadata": {
        "id": "t9WGTHs2czZ2"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L=LSTM_Object(test_1)\n",
        "L.prescale()"
      ],
      "metadata": {
        "id": "n2sIXmnmcu0G"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L.ret_learning()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U90UHk_awQox",
        "outputId": "b9beb63d-9809-433e-ff01-d2c02e5dbf6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.6876\n",
            "Epoch 1: val_loss improved from inf to 0.65558, saving model to tmp/ckeckpointer.ckpt\n",
            "4/4 [==============================] - 15s 2s/step - loss: 0.6870 - val_loss: 0.6556\n",
            "Epoch 2/1000\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.6494\n",
            "Epoch 2: val_loss improved from 0.65558 to 0.63669, saving model to tmp/ckeckpointer.ckpt\n",
            "4/4 [==============================] - 2s 688ms/step - loss: 0.6481 - val_loss: 0.6367\n",
            "Epoch 3/1000\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.6350\n",
            "Epoch 3: val_loss improved from 0.63669 to 0.62107, saving model to tmp/ckeckpointer.ckpt\n",
            "4/4 [==============================] - 3s 1s/step - loss: 0.6343 - val_loss: 0.6211\n",
            "Epoch 4/1000\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.6064\n",
            "Epoch 4: val_loss improved from 0.62107 to 0.58219, saving model to tmp/ckeckpointer.ckpt\n",
            "4/4 [==============================] - 5s 2s/step - loss: 0.6047 - val_loss: 0.5822\n",
            "Epoch 5/1000\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.5832\n",
            "Epoch 5: val_loss improved from 0.58219 to 0.56057, saving model to tmp/ckeckpointer.ckpt\n",
            "4/4 [==============================] - 5s 2s/step - loss: 0.5817 - val_loss: 0.5606\n",
            "Epoch 6/1000\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.5616\n",
            "Epoch 6: val_loss improved from 0.56057 to 0.55566, saving model to tmp/ckeckpointer.ckpt\n",
            "4/4 [==============================] - 5s 2s/step - loss: 0.5609 - val_loss: 0.5557\n",
            "Epoch 7/1000\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.5517\n",
            "Epoch 7: val_loss improved from 0.55566 to 0.54319, saving model to tmp/ckeckpointer.ckpt\n",
            "4/4 [==============================] - 5s 2s/step - loss: 0.5506 - val_loss: 0.5432\n",
            "Epoch 8/1000\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.5383\n",
            "Epoch 8: val_loss improved from 0.54319 to 0.52802, saving model to tmp/ckeckpointer.ckpt\n",
            "4/4 [==============================] - 5s 2s/step - loss: 0.5373 - val_loss: 0.5280\n",
            "Epoch 9/1000\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.5284\n",
            "Epoch 9: val_loss improved from 0.52802 to 0.52305, saving model to tmp/ckeckpointer.ckpt\n",
            "4/4 [==============================] - 2s 735ms/step - loss: 0.5276 - val_loss: 0.5230\n",
            "Epoch 10/1000\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.5247\n",
            "Epoch 10: val_loss improved from 0.52305 to 0.51727, saving model to tmp/ckeckpointer.ckpt\n",
            "4/4 [==============================] - 3s 1s/step - loss: 0.5238 - val_loss: 0.5173\n",
            "Epoch 11/1000\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.5168\n",
            "Epoch 11: val_loss improved from 0.51727 to 0.51437, saving model to tmp/ckeckpointer.ckpt\n",
            "4/4 [==============================] - 5s 2s/step - loss: 0.5161 - val_loss: 0.5144\n",
            "Epoch 12/1000\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.5150\n",
            "Epoch 12: val_loss did not improve from 0.51437\n",
            "4/4 [==============================] - 0s 119ms/step - loss: 0.5143 - val_loss: 0.5155\n",
            "Epoch 13/1000\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.5151\n",
            "Epoch 13: val_loss improved from 0.51437 to 0.51212, saving model to tmp/ckeckpointer.ckpt\n",
            "4/4 [==============================] - 2s 640ms/step - loss: 0.5144 - val_loss: 0.5121\n",
            "Epoch 14/1000\n",
            "3/4 [=====================>........] - ETA: 0s - loss: 0.5120\n",
            "Epoch 14: val_loss improved from 0.51212 to 0.51150, saving model to tmp/ckeckpointer.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pF08_5pC6656"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}