{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl1xbFVCPtKO"
      },
      "source": [
        "## LSTM class Developed\n",
        "-----------------------------\n",
        "[feat] 7/16\n",
        "- ! to prevent overfitting use K-fold, validation split ! <- NEED TO DEVELOP\n",
        "- basical LSTM model => lstm dense need to doubled\n",
        "- not tested\n",
        "- without AOC, interest rate\n",
        "- bidirectional LSTM Model\n",
        "\n",
        "[feat] 7/17\n",
        "\n",
        "[need] 7/17\n",
        "- val_loss 범위 설정\n",
        "- k-fold 구현-> LSTM 구조상 폐기\n",
        "- return값 설정\n",
        "- 모델 예측 설정 방법\n",
        "\n",
        "\n",
        "#### 7/19 V 1.0\n",
        "[feat]\n",
        "- postscale...      (done)\n",
        "- model test res... (done)\n",
        "- predict range .. (done) (using loss mean square err)\n",
        "\n",
        "[need] 7/19 V 1.0\n",
        "- prediction res return function => ??input??\n",
        "-\n",
        "[feat] V 1.0.1\n",
        "- visiualization update\n",
        "- check res (Request)\n",
        "\n",
        "[feat] V 1.0.2\n",
        "- loss calc func\n",
        "- get tested output\n",
        "\n",
        "#### 7/20\n",
        "[feat & perf] V 1.1.0\n",
        "- optimizated\n",
        "- instanced model\n",
        "- model complete\n",
        "\n",
        "[need] V 1.1.0\n",
        "- need to develop model quality\n",
        "- sort & compedit gap values with prophet\n",
        "\n",
        "if prophet is batter than LSTM use Prophet (by watching res)\n",
        "\n",
        "\n",
        "--------------------------------------------------------\n",
        "#### For ansj\n",
        "- poltting testset\n",
        "- batch = 500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53a68bbqPzrK"
      },
      "source": [
        "imorts & get datas\n",
        "------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IyhvmWrGQ-rS"
      },
      "outputs": [],
      "source": [
        "#!pip install -U finance-datareader\n",
        "\n",
        "#%pip install FinanceDataReader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bDqimijIQjdY"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-22 18:36:20.221053: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-07-22 18:36:20.222775: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-07-22 18:36:20.257190: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-07-22 18:36:20.257789: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-22 18:36:20.921832: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "#import pandas_datareader as pdr\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense ,LSTM, Dropout,Bidirectional\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from tensorflow import expand_dims\n",
        "from tensorflow.keras.losses import Huber\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from os.path import join\n",
        "from tensorflow import constant\n",
        "from time import sleep\n",
        "#import FinanceDataReader as fdr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-_pxjz3BPYpb"
      },
      "outputs": [],
      "source": [
        "path=\"~/Desktop/2023_1st_vacation/KRX_py/KRX_DATA/open/train.csv\" # path = dataset path(google drive)\n",
        "data=pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Xg6dg09IUovd"
      },
      "outputs": [],
      "source": [
        "# prescaler\n",
        "def getAOC(data):\n",
        "  AOC = []\n",
        "  close = data['종가']\n",
        "  close_pre = close.shift(1)\n",
        "\n",
        "  AOC.append(0)\n",
        "\n",
        "  # aoc = (금일 종가 - 전일 종가) / 전일 종가\n",
        "  for i in range(1, len(close)):\n",
        "    aoc_value = ((close[i] - close_pre[i]) / close_pre[i]) * 100\n",
        "    AOC.append(aoc_value)\n",
        "\n",
        "  return AOC\n",
        "\n",
        "#sort data by \"종목명\"\n",
        "subject_Data=data.sort_values(by=\"종목명\",inplace=False)\n",
        "subject_Data.head()\n",
        "subject_Data.columns\n",
        "\n",
        "pv_s_data=pd.pivot_table(subject_Data,values=['거래량', '시가', '고가', '저가', '종가'],index=['종목코드','일자'])\n",
        "\n",
        "divided = pv_s_data.index.get_level_values('종목코드').unique()\n",
        "\n",
        "sliced_dataframes = []\n",
        "\n",
        "for i in divided:\n",
        "    sliced_data = pv_s_data.loc[i]\n",
        "    sliced_dataframe = sliced_data.reset_index()\n",
        "    sliced_dataframes.append(sliced_dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xseyDtvDYM00",
        "outputId": "d400106b-6969-4780-9e48-5e4266f7a62c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['거래량', '고가', '시가', '저가'], dtype='object')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sliced_dataframes[0].columns[1:-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF-DvmbKYcLv"
      },
      "source": [
        "## LSTM Obj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rqz4N2_IVacg"
      },
      "outputs": [],
      "source": [
        "class LSTM_Object():\n",
        "\n",
        "  def __init__(self,data):\n",
        "    #get sliced data\n",
        "    self.data=data\n",
        "\n",
        "  def modeling(self):\n",
        "\n",
        "    self.prescale()\n",
        "    self.model=Sequential()\n",
        "    #layers\n",
        "    self.model.add(Bidirectional(LSTM(1024,return_sequences=True,input_shape=(self.time_steps, self.num_features))))\n",
        "    self.model.add(Dense(512, activation='relu'))\n",
        "    self.model.add(Dense(256, activation='relu'))\n",
        "    self.model.add(Dense(128, activation='relu'))\n",
        "    self.model.add(Dense(64, activation='relu'))\n",
        "    self.model.add(Dense(32, activation='relu'))\n",
        "\n",
        "    model_save_path='/content/drive/MyDrive/2023_1st_vac/KRX_modelings/tests'\n",
        "\n",
        "    #output layer\n",
        "    self.model.add(Dense(1, activation='relu'))\n",
        "    self.filename = join(model_save_path, 'ckeckpointer.ckpt')\n",
        "    checkpoint = ModelCheckpoint(self.filename, save_weights_only=True, save_best_only=True,monitor='val_loss',verbose=0)\n",
        "\n",
        "    earlystopping = EarlyStopping(monitor='val_loss', patience=100)\n",
        "    self.model.compile(loss = 'mean_squared_error', optimizer=Adam(learning_rate=0.001))\n",
        "    self.history=self.model.fit(self.x_train,self.y_train,epochs=500,batch_size=128,validation_data=(self.x_val,self.y_val),shuffle=False,callbacks=[checkpoint, earlystopping],verbose=0)\n",
        "\n",
        "\n",
        "  def prescale(self):\n",
        "    x_scaler = MinMaxScaler()\n",
        "    self.y_scaler = MinMaxScaler()\n",
        "    # Scaling features\n",
        "    x_data = self.data[self.data.columns[1:-1]]\n",
        "    x_data = x_scaler.fit_transform(x_data)\n",
        "    # Scaling target variable\n",
        "    y_data = self.data['종가']\n",
        "    y_data = self.y_scaler.fit_transform(y_data.values.reshape(-1, 1))\n",
        "    # validation set\n",
        "    x_train_p, x_test, y_train_p, y_test = train_test_split(x_data, y_data, test_size=0.2, shuffle=False)\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x_train_p, y_train_p, test_size=0.25, shuffle=False)\n",
        "    __t,x_final,__t,__t=train_test_split(x_data, y_data, test_size=30/len(y_data), shuffle=False)\n",
        "\n",
        "    ### reshape input datas()\n",
        "\n",
        "\n",
        "    self.num_features = x_data.shape[1]\n",
        "    self.num_samples=x_data.shape[0]\n",
        "    self.time_steps=30\n",
        "\n",
        "    self.x_train = self.create_sequences(x_train)\n",
        "    self.x_test = self.create_sequences(x_test)\n",
        "    self.x_val = self.create_sequences(x_val)\n",
        "    self.x_final = self.create_sequences(x_final)\n",
        "\n",
        "    self.y_train=self.create_sequences(y_train)\n",
        "    self.y_test=self.create_sequences(y_test)\n",
        "    self.y_val=self.create_sequences(y_val)\n",
        "\n",
        "\n",
        "\n",
        "  def create_sequences(self, data):\n",
        "    num_samples, num_features = data.shape\n",
        "    sequences = []\n",
        "    for i in range(num_samples - self.time_steps +1):\n",
        "      sequences.append(data[i:i + self.time_steps, :])\n",
        "    return np.array(sequences)\n",
        "\n",
        "  def inverse_sequences(self,data_sequences):\n",
        "    num_samples, num_steps, num_features = data_sequences.shape\n",
        "    data = np.zeros((num_samples + self.time_steps - 1, num_features))\n",
        "    for i in range(num_samples):\n",
        "      data[i:i + self.time_steps, :] += data_sequences[i, :, :]\n",
        "    data /= self.time_steps\n",
        "    return data[:num_samples]\n",
        "    #frquency domain inverse laplace transform\n",
        "\n",
        "  def ret_learning(self):\n",
        "    # rescale to get real value\n",
        "    self.modeling()\n",
        "    sleep(0.5)\n",
        "    self.model.load_weights(self.filename)\n",
        "    pred = self.model.predict(self.x_test)\n",
        "    sleep(0.5)\n",
        "    rescaled_pred = self.y_scaler.inverse_transform(self.inverse_sequences(pred).reshape(-1,1))\n",
        "    rescaled_real = self.y_scaler.inverse_transform(self.inverse_sequences(self.y_test).reshape(-1,1))\n",
        "    sleep(0.5)\n",
        "\n",
        "    #real-pred to get resonable value (later)\n",
        "    k=0\n",
        "    sum=0\n",
        "    for p in rescaled_pred:\n",
        "      sum+=abs(rescaled_real[k]-p)\n",
        "      k+=1\n",
        "    gap=sum/(k+1)\n",
        "\n",
        "    plt.figure(figsize=(12, 9))\n",
        "    plt.plot(rescaled_real, label='actual')\n",
        "    plt.plot(rescaled_pred, label='prediction')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    #rescaled_pred\n",
        "    return gap\n",
        "\n",
        "  def predict_after_30days(self):\n",
        "    _ , gap = self.ret_learning()\n",
        "    self.model.load_weights(self.filename)\n",
        "    pred_30 = self.model.predict(self.x_final)\n",
        "    pred_30 = self.y_scaler.inverse_transform(self.inverse_sequences(pred_30).reshape(-1,1))\n",
        "    pred_30=pred_30[-1]\n",
        "    return pred_30,gap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "M89z3rRbFIKt"
      },
      "outputs": [],
      "source": [
        "L=LSTM_Object(sliced_dataframes[0])\n",
        "L.prescale()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(267, 30, 4)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "L.x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "종목코드    A060310\n",
            "Name: 0, dtype: object\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-22 18:19:24.996690: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-07-22 18:19:24.999421: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-07-22 18:19:25.000431: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-07-22 18:19:25.119032: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
            "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
            "2023-07-22 18:19:25.158970: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-07-22 18:19:25.160443: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-07-22 18:19:25.161511: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-07-22 18:19:25.417380: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-07-22 18:19:25.418905: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-07-22 18:19:25.419926: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-07-22 18:19:25.539858: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
            "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
            "2023-07-22 18:19:25.583424: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-07-22 18:19:25.584565: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-07-22 18:19:25.585620: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-07-22 18:19:26.106450: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
            "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
            "2023-07-22 18:19:26.597128: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-07-22 18:19:26.600501: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-07-22 18:19:26.602237: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-07-22 18:19:26.729026: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
            "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
            "2023-07-22 18:19:26.775207: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-07-22 18:19:26.776356: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-07-22 18:19:26.777345: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-07-22 18:19:27.295623: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
            "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
            "2023-07-22 18:19:31.887111: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-07-22 18:19:31.888402: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-07-22 18:19:31.889260: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
            "2023-07-22 18:19:32.007696: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
            "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
            "2023-07-22 18:19:32.044280: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
            "2023-07-22 18:19:32.045184: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
            "2023-07-22 18:19:32.046012: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
            "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
          ]
        },
        {
          "ename": "PermissionDeniedError",
          "evalue": "/content; Permission denied",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPermissionDeniedError\u001b[0m                     Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(labels\u001b[39m.\u001b[39miloc[i])\n\u001b[1;32m      4\u001b[0m L\u001b[39m=\u001b[39mLSTM_Object(d)\n\u001b[0;32m----> 5\u001b[0m \u001b[39mprint\u001b[39m(L\u001b[39m.\u001b[39;49mret_learning())\n\u001b[1;32m      6\u001b[0m i\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n",
            "Cell \u001b[0;32mIn[14], line 81\u001b[0m, in \u001b[0;36mLSTM_Object.ret_learning\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mret_learning\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     80\u001b[0m   \u001b[39m# rescale to get real value\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodeling()\n\u001b[1;32m     82\u001b[0m   sleep(\u001b[39m0.5\u001b[39m)\n\u001b[1;32m     83\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mload_weights(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilename)\n",
            "Cell \u001b[0;32mIn[14], line 28\u001b[0m, in \u001b[0;36mLSTM_Object.modeling\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m earlystopping \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mcompile(loss \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmean_squared_error\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m))\n\u001b[0;32m---> 28\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhistory\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx_train,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my_train,epochs\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m,batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m,validation_data\u001b[39m=\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx_val,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my_val),shuffle\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,callbacks\u001b[39m=\u001b[39;49m[checkpoint, earlystopping],verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
            "File \u001b[0;32m~/anaconda3/envs/KRX_python/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/anaconda3/envs/KRX_python/lib/python3.9/site-packages/tensorflow/python/lib/io/file_io.py:513\u001b[0m, in \u001b[0;36mrecursive_create_dir_v2\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mio.gfile.makedirs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    502\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrecursive_create_dir_v2\u001b[39m(path):\n\u001b[1;32m    503\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a directory and all parent/intermediate directories.\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \n\u001b[1;32m    505\u001b[0m \u001b[39m  It succeeds if path already exists and is writable.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[39m    errors.OpError: If the operation fails.\u001b[39;00m\n\u001b[1;32m    512\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 513\u001b[0m   _pywrap_file_io\u001b[39m.\u001b[39;49mRecursivelyCreateDir(compat\u001b[39m.\u001b[39;49mpath_to_bytes(path))\n",
            "\u001b[0;31mPermissionDeniedError\u001b[0m: /content; Permission denied"
          ]
        }
      ],
      "source": [
        "i=0\n",
        "for d in sliced_dataframes:\n",
        "    print(labels.iloc[i])\n",
        "    L=LSTM_Object(d)\n",
        "    print(L.ret_learning())\n",
        "    i+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_oAc1VC9txT"
      },
      "source": [
        "test shell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZTRyFJU9V3C",
        "outputId": "b0065141-4f4b-4148-f867-3c5c999cd80a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "종목코드    A060310\n",
            "Name: 0, dtype: object\n",
            "3/3 [==============================] - 4s 949ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([8170.])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_list=[]\n",
        "gap_acc=[]\n",
        "\n",
        "test=sliced_dataframes[0]\n",
        "print(labels.iloc[0])\n",
        "LSTM_model=LSTM_Object(test)\n",
        "\n",
        "pred,gap = LSTM_model.predict_after_30days()\n",
        "\n",
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "p0n8S46j2-hs",
        "outputId": "41ac2500-a421-4e30-b477-8cc193648a5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "종목코드    A060310\n",
            "Name: 0, dtype: object\n",
            "3/3 [==============================] - 3s 448ms/step\n",
            "종목코드    A095570\n",
            "Name: 1, dtype: object\n",
            "3/3 [==============================] - 2s 443ms/step\n",
            "종목코드    A006840\n",
            "Name: 2, dtype: object\n",
            "3/3 [==============================] - 3s 474ms/step\n",
            "종목코드    A054620\n",
            "Name: 3, dtype: object\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7e2550d2a320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7e2550d2af80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7e254f862710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 3s 487ms/step\n",
            "종목코드    A265520\n",
            "Name: 4, dtype: object\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7e254d97a3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7e25500ea710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7e2550e7e950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 4s 827ms/step\n",
            "종목코드    A211270\n",
            "Name: 5, dtype: object\n",
            "3/3 [==============================] - 3s 478ms/step\n",
            "종목코드    A027410\n",
            "Name: 6, dtype: object\n",
            "3/3 [==============================] - 2s 394ms/step\n",
            "종목코드    A282330\n",
            "Name: 7, dtype: object\n",
            "3/3 [==============================] - 2s 395ms/step\n",
            "종목코드    A126600\n",
            "Name: 8, dtype: object\n",
            "3/3 [==============================] - 3s 505ms/step\n",
            "종목코드    A138930\n",
            "Name: 9, dtype: object\n",
            "3/3 [==============================] - 3s 496ms/step\n",
            "종목코드    A001460\n",
            "Name: 10, dtype: object\n",
            "3/3 [==============================] - 3s 433ms/step\n",
            "종목코드    A013720\n",
            "Name: 11, dtype: object\n",
            "3/3 [==============================] - 2s 463ms/step\n",
            "종목코드    A001040\n",
            "Name: 12, dtype: object\n",
            "3/3 [==============================] - 3s 428ms/step\n",
            "종목코드    A079160\n",
            "Name: 13, dtype: object\n",
            "3/3 [==============================] - 3s 467ms/step\n",
            "종목코드    A035760\n",
            "Name: 14, dtype: object\n",
            "3/3 [==============================] - 3s 615ms/step\n",
            "종목코드    A311690\n",
            "Name: 15, dtype: object\n",
            "3/3 [==============================] - 7s 1s/step\n",
            "종목코드    A000120\n",
            "Name: 16, dtype: object\n",
            "3/3 [==============================] - 2s 439ms/step\n",
            "종목코드    A011150\n",
            "Name: 17, dtype: object\n",
            "3/3 [==============================] - 4s 485ms/step\n",
            "종목코드    A097950\n",
            "Name: 18, dtype: object\n",
            "3/3 [==============================] - 2s 392ms/step\n",
            "종목코드    A051500\n",
            "Name: 19, dtype: object\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-36c3ab2a3a2e>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m#결과랑 실제 값이랑 같게 나오도록 코드 수정해줘 -민 // 슬라이스 내가 한거 아니라 수정하기 싫..\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mLSTM_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLSTM_Object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mret_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0midx\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-201035117824>\u001b[0m in \u001b[0;36mret_learning\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mret_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# rescale to get real value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-201035117824>\u001b[0m in \u001b[0;36mmodeling\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mearlystopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearlystopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/layers/rnn/lstm.py\", line 695, in call\n        self.cell.recurrent_kernel\n\n    AttributeError: Exception encountered when calling layer 'forward_lstm_20' (type LSTM).\n    \n    'LSTMCell' object has no attribute 'recurrent_kernel'\n    \n    Call arguments received by layer 'forward_lstm_20' (type LSTM):\n      • inputs=tf.Tensor(shape=(None, 30, 4), dtype=float32)\n      • mask=None\n      • training=True\n      • initial_state=None\n"
          ]
        }
      ],
      "source": [
        "idx=0\n",
        "\n",
        "pred_list=[]\n",
        "gap_acc=[]\n",
        "out_labels=[]\n",
        "for c in sliced_dataframes:\n",
        "  print(labels.iloc[idx])     #결과랑 실제 값이랑 같게 나오도록 코드 수정해줘 -민 // 슬라이스 내가 한거 아니라 수정하기 싫..\n",
        "  LSTM_model=LSTM_Object(c)\n",
        "  pred,gap = LSTM_model.ret_learning()\n",
        "  idx+=1\n",
        "  out_labels.append(labels.iloc[idx])\n",
        "  sleep(2)\n",
        "  pred_list.append(pred)\n",
        "  gap_acc.append(gap)\n",
        "  #to prevent model corrupting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AsOnr2sKu6p"
      },
      "source": [
        "###  output code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wOarADtAlF7"
      },
      "outputs": [],
      "source": [
        "df=pd.dataframe(\n",
        "    {\n",
        "        '종목코드': out_labels,\n",
        "        '종가': pred_list\n",
        "    }\n",
        ")\n",
        "\n",
        "df.sort_values(by='종가')\n",
        "df_out=df[['종목코드']]\n",
        "df_out.to_csv('/content/drive/MyDrive/2023_1st_vac/KRX_modelings/csv_outputs',index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fs0gmL-yFBrz"
      },
      "outputs": [],
      "source": [
        "labels.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vr6lNO-YFfbh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
